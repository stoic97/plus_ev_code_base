{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16dbbd53013641d88ee043609aa54256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf5865398ffb48c6a1dcad213b951e60",
              "IPY_MODEL_6adb92deaf3f4c01ad15258ddb296a42",
              "IPY_MODEL_5d0e47cc51b2486187a4989d8d2343f4"
            ],
            "layout": "IPY_MODEL_7b46f869969b49f7bff2210ccd03521d"
          }
        },
        "bf5865398ffb48c6a1dcad213b951e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b07a5fa89484b6ea1395bb0ddad0de8",
            "placeholder": "​",
            "style": "IPY_MODEL_6810bdb579424f49b519d1fc8b9919c9",
            "value": "Forecasting Progress:  95%"
          }
        },
        "6adb92deaf3f4c01ad15258ddb296a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a48c84c85efd4b9aa927cc2eeca01b58",
            "max": 30811,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33c05b0dc15b439fbe3440babbf9d59f",
            "value": 29232
          }
        },
        "5d0e47cc51b2486187a4989d8d2343f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9a722765b8b4b378fb516f11779e01f",
            "placeholder": "​",
            "style": "IPY_MODEL_da328b2722e3478e8a873f02ce80d654",
            "value": " 29232/30811 [1:56:53&lt;06:47,  3.88it/s]"
          }
        },
        "7b46f869969b49f7bff2210ccd03521d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b07a5fa89484b6ea1395bb0ddad0de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6810bdb579424f49b519d1fc8b9919c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a48c84c85efd4b9aa927cc2eeca01b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33c05b0dc15b439fbe3440babbf9d59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9a722765b8b4b378fb516f11779e01f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da328b2722e3478e8a873f02ce80d654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "Fz4j3lFf6sIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZTfGZ_s1iwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34788bf2-cdcd-424e-c539-32132876426a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WandB setup complete!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "y# @title\n",
        "# Add this at the start of your notebook\n",
        "def setup_wandb():\n",
        "    try:\n",
        "        import wandb\n",
        "        # Check if already logged in\n",
        "        if wandb.api.api_key is None:\n",
        "            # Your API key\n",
        "            WANDB_API_KEY = \"641b305133f7d8345e710ecf6c9d83fea7e225f1\"\n",
        "            os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
        "\n",
        "        print(\"WandB setup complete!\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up WandB: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# Use it in your notebook\n",
        "setup_wandb()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# taking input of the file\n",
        "csv_path = \"/content/nifty50_1min_2015_to_2024.csv\"\n",
        "base_data = pd.read_csv(csv_path)\n",
        "df = base_data.copy()\n",
        "\n",
        "# ## creating a sample dataframe so that I can dry run the code for leser computation\n",
        "# sample_point = len(df)//5\n",
        "# df_sample = df[:sample_point]\n",
        "\n",
        "# Create a clean copy and handle datetime with timezone\n",
        "df = df.copy()\n",
        "df.loc[:, 'date'] = pd.to_datetime(df['date'])\n",
        "df = df.set_index('date')\n",
        "\n",
        "# Resample to 5min (preserving timezone)\n",
        "df_5min = df.resample('5min', closed='left', label='left').agg({\n",
        "    'open': 'first',\n",
        "    'high': 'max',\n",
        "    'low': 'min',\n",
        "    'close': 'last',\n",
        "    'volume': 'sum'\n",
        "}).dropna()\n",
        "\n",
        "# If you need to remove timezone, uncomment the next line:\n",
        "# df_5min.index = df_5min.index.tz_localize(None)\n",
        "\n",
        "print(\"Original shape:\", df.shape)\n",
        "print(\"New 5-min shape:\", df_5min.shape)\n",
        "print(\"\\nFirst few rows of 5-min data:\")\n",
        "print(df_5min.head())\n",
        "\n",
        "\n",
        "# Calculate returns while preserving the index\n",
        "returns_df = pd.DataFrame()\n",
        "returns_df['returns'] = df_5min['close'].pct_change()\n",
        "returns_df = returns_df.dropna()\n",
        "\n",
        "print(\"Shape of returns dataframe:\", returns_df.shape)\n",
        "print(\"\\nFirst few returns (should show % changes between the close prices we saw):\")\n",
        "print(returns_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNiBycy4OCxq",
        "outputId": "a1888b31-726e-459e-83d6-983a53676393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
            "  return Index(sequences[0], name=names)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (890511, 5)\n",
            "New 5-min shape: (178118, 5)\n",
            "\n",
            "First few rows of 5-min data:\n",
            "                              open     high      low    close  volume\n",
            "date                                                                 \n",
            "2015-01-09 09:15:00+05:30  8285.45  8301.30  8285.45  8301.20       0\n",
            "2015-01-09 09:20:00+05:30  8300.50  8303.00  8293.25  8301.00       0\n",
            "2015-01-09 09:25:00+05:30  8301.65  8302.55  8286.80  8294.15       0\n",
            "2015-01-09 09:30:00+05:30  8294.10  8295.75  8280.65  8288.50       0\n",
            "2015-01-09 09:35:00+05:30  8289.10  8290.45  8278.00  8283.45       0\n",
            "Shape of returns dataframe: (178117, 1)\n",
            "\n",
            "First few returns (should show % changes between the close prices we saw):\n",
            "                            returns\n",
            "date                               \n",
            "2015-01-09 09:20:00+05:30 -0.000024\n",
            "2015-01-09 09:25:00+05:30 -0.000825\n",
            "2015-01-09 09:30:00+05:30 -0.000681\n",
            "2015-01-09 09:35:00+05:30 -0.000609\n",
            "2015-01-09 09:40:00+05:30  0.000254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = returns_df.tail(4800)"
      ],
      "metadata": {
        "id": "XjEuYOotOSLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "48*5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1CRXZsqSNvc",
        "outputId": "1a230c49-9cdd-44d4-cda9-d751b30eadb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "240"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from tqdm import tqdm\n",
        "import multiprocessing\n",
        "from joblib import Parallel, delayed\n",
        "import wandb\n",
        "from typing import Dict, Tuple, List\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Suppress model convergence warnings\n",
        "\n",
        "CONFIG = {\n",
        "    \"initial_train_months\": 6,\n",
        "    \"rolling_window_months\": 6,\n",
        "    \"step_size_months\": 1,\n",
        "    \"forecast_horizons\": [1, 2, 3],\n",
        "    \"trading_days_per_month\": 21,\n",
        "    \"intervals_per_day\": 12,\n",
        "    \"models\": {\n",
        "        \"arima\": {\"order\": (2, 0, 2)},\n",
        "        \"sarima\": {\"order\": (2, 0, 2), \"seasonal_order\": (2, 0, 2, 60)}\n",
        "    },\n",
        "    \"plot_sample_size\": 1000,\n",
        "    \"n_jobs\": multiprocessing.cpu_count() - 1,\n",
        "    \"gpu_batch_size\": 4096\n",
        "}\n",
        "\n",
        "def period_calculator(months: int) -> int:\n",
        "    return int(months * CONFIG[\"trading_days_per_month\"] * CONFIG[\"intervals_per_day\"])\n",
        "\n",
        "CONFIG[\"rolling_window_periods\"] = period_calculator(CONFIG[\"rolling_window_months\"])\n",
        "CONFIG[\"step_size_periods\"] = period_calculator(CONFIG[\"step_size_months\"])\n",
        "CONFIG[\"initial_train_periods\"] = period_calculator(CONFIG[\"initial_train_months\"])\n",
        "\n",
        "class GPUMemoryContext:\n",
        "    def __enter__(self):\n",
        "        self.pool = cp.get_default_memory_pool()\n",
        "        self.initial_used = self.pool.used_bytes()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        self.pool.free_all_blocks()\n",
        "\n",
        "class PortfolioTracker:\n",
        "    def __init__(self, initial_capital=1e6):\n",
        "        self.value = cp.asarray(initial_capital, dtype=cp.float32)\n",
        "        self.drawdown = cp.asarray(0.0, dtype=cp.float32)\n",
        "        self.peak_value = cp.asarray(initial_capital, dtype=cp.float32)\n",
        "\n",
        "    def update(self, returns, position_size):\n",
        "        # GPU-accelerated portfolio update\n",
        "        self.value *= (1 + returns * position_size)\n",
        "        self.peak_value = cp.maximum(self.peak_value, self.value)\n",
        "        self.drawdown = (self.peak_value - self.value) / self.peak_value\n",
        "\n",
        "class BaseModel:\n",
        "    def __init__(self, model_config: Dict):\n",
        "        self.config = model_config\n",
        "        self.model = None\n",
        "        self._last_gpu_residuals = None\n",
        "        self._last_gpu_fitted = None\n",
        "        self._memory_pool = cp.get_default_memory_pool()\n",
        "        self._pinned_pool = cp.get_default_pinned_memory_pool()\n",
        "        self._peak_memory_usage = 0\n",
        "        self._current_memory_usage = 0\n",
        "        total_memory = cp.cuda.runtime.memGetInfo()[1]\n",
        "        self._memory_threshold = int(0.8 * total_memory)\n",
        "\n",
        "    def _monitor_memory_usage(self):\n",
        "        \"\"\"Track current and peak memory usage\"\"\"\n",
        "        current = self._memory_pool.used_bytes()\n",
        "        self._current_memory_usage = current\n",
        "        self._peak_memory_usage = max(self._peak_memory_usage, current)\n",
        "\n",
        "        if current > self._memory_threshold:\n",
        "            self._cleanup_gpu_memory()\n",
        "            raise cp.cuda.memory.OutOfMemoryError(\"Memory usage exceeded threshold\")\n",
        "\n",
        "    def _get_available_memory(self) -> int:\n",
        "        \"\"\"Get available GPU memory in bytes\"\"\"\n",
        "        free, total = cp.cuda.runtime.memGetInfo()\n",
        "        return free\n",
        "\n",
        "    def _cleanup_gpu_memory(self):\n",
        "        \"\"\"Enhanced memory cleanup\"\"\"\n",
        "        try:\n",
        "            # Clear specific arrays\n",
        "            if hasattr(self, '_last_gpu_residuals'):\n",
        "                del self._last_gpu_residuals\n",
        "            if hasattr(self, '_last_gpu_fitted'):\n",
        "                del self._last_gpu_fitted\n",
        "\n",
        "            # Force garbage collection\n",
        "            import gc\n",
        "            gc.collect()\n",
        "\n",
        "            # Clear memory pools\n",
        "            self._memory_pool.free_all_blocks()\n",
        "            self._pinned_pool.free_all_blocks()\n",
        "\n",
        "            # Synchronize device\n",
        "            cp.cuda.runtime.deviceSynchronize()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during memory cleanup: {str(e)}\")\n",
        "\n",
        "\n",
        "    def train(self, data: pd.Series) -> bool:\n",
        "        try:\n",
        "            # Ensure we're on the right device and manage memory\n",
        "            with cp.cuda.Device(0):\n",
        "                # Monitor memory before operations\n",
        "                self._monitor_memory_usage()\n",
        "                # Clean up any previous GPU arrays\n",
        "                self._cleanup_gpu_memory()\n",
        "\n",
        "                # Transfer data to GPU efficiently\n",
        "                if isinstance(data, cp.ndarray):\n",
        "                    training_data = cp.asnumpy(data)  # Single transfer\n",
        "                else:\n",
        "                    training_data = data.values if isinstance(data, pd.Series) else data\n",
        "\n",
        "                # Train the model\n",
        "                self.model = SARIMAX(\n",
        "                    training_data,\n",
        "                    order=self.config.get('order', (0,0,0)),\n",
        "                    seasonal_order=self.config.get('seasonal_order', None),\n",
        "                    enforce_stationarity=False,\n",
        "                    enforce_invertibility=False\n",
        "                ).fit(disp=False)\n",
        "\n",
        "                # Store residuals and fitted values on GPU efficiently\n",
        "                try:\n",
        "                    # Batch transfer to GPU\n",
        "                    self._last_gpu_residuals = cp.asarray(self.model.resid, dtype=cp.float32)\n",
        "                    self._last_gpu_fitted = cp.asarray(self.model.fittedvalues, dtype=cp.float32)\n",
        "                except cp.cuda.memory.OutOfMemoryError:\n",
        "                    # If OOM occurs, try to recover\n",
        "                    self._cleanup_gpu_memory()\n",
        "                    # Retry with smaller chunks if needed\n",
        "                    chunk_size = len(self.model.resid) // 2\n",
        "                    self._last_gpu_residuals = cp.asarray(self.model.resid[:chunk_size], dtype=cp.float32)\n",
        "                    self._last_gpu_fitted = cp.asarray(self.model.fittedvalues[:chunk_size], dtype=cp.float32)\n",
        "\n",
        "                # Monitor memory after major operations\n",
        "                self._monitor_memory_usage()\n",
        "\n",
        "                return True\n",
        "\n",
        "        except cp.cuda.memory.OutOfMemoryError as e:\n",
        "            print(f\"Out of memory during training: {str(e)}\")\n",
        "            self._cleanup_gpu_memory()\n",
        "            # Try to recover with smaller batch\n",
        "            return self._train_with_reduced_batch(data)\n",
        "        except Exception as e:\n",
        "            print(f\"Training failed: {str(e)}\")\n",
        "            self._cleanup_gpu_memory()\n",
        "            return False\n",
        "\n",
        "    def forecast(self, steps: int) -> cp.ndarray:\n",
        "        try:\n",
        "            with cp.cuda.Device(0):\n",
        "                if self.model:\n",
        "                    # Generate forecast\n",
        "                    forecast_result = self.model.forecast(steps=steps)\n",
        "\n",
        "                    # Transfer to GPU and handle memory\n",
        "                    try:\n",
        "                        gpu_forecast = cp.asarray(forecast_result, dtype=cp.float32)\n",
        "                        return gpu_forecast\n",
        "                    except cp.cuda.memory.OutOfMemoryError:\n",
        "                        self._cleanup_gpu_memory()\n",
        "                        # Retry after cleanup\n",
        "                        return cp.asarray(forecast_result, dtype=cp.float32)\n",
        "                return cp.full(steps, cp.nan, dtype=cp.float32)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Forecast failed: {str(e)}\")\n",
        "            self._cleanup_gpu_memory()\n",
        "            return cp.full(steps, cp.nan, dtype=cp.float32)\n",
        "\n",
        "    def _train_with_reduced_batch(self, data):\n",
        "        \"\"\"Handle OOM by reducing training window\"\"\"\n",
        "        reduced_window = len(data) // 2\n",
        "        try:\n",
        "            return self.train(data[-reduced_window:])\n",
        "        except Exception as e:\n",
        "            print(f\"Reduced training failed: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def get_regression_metrics(self) -> Dict:\n",
        "        \"\"\"Calculate comprehensive regression metrics including covariance for decision layer\"\"\"\n",
        "        try:\n",
        "            with cp.cuda.Device(0):\n",
        "                if not self.model or self._last_gpu_residuals is None:\n",
        "                    return self._get_empty_metrics()\n",
        "\n",
        "                # Reuse cached GPU arrays\n",
        "                residuals = self._last_gpu_residuals\n",
        "                predictions = self._last_gpu_fitted\n",
        "\n",
        "                # Calculate forecast statistics\n",
        "                forecast_horizons = CONFIG[\"forecast_horizons\"]\n",
        "                forecast_results = self.model.get_forecast(steps=max(forecast_horizons))\n",
        "\n",
        "                try:\n",
        "                    # Batch transfer forecast statistics to GPU\n",
        "                    gpu_variances = cp.asarray([forecast_results.var[h-1] for h in forecast_horizons], dtype=cp.float32)\n",
        "                    gpu_covariance = cp.asarray(forecast_results.cov, dtype=cp.float32)\n",
        "\n",
        "                    # Calculate metrics on GPU\n",
        "                    gpu_mse = cp.mean(residuals ** 2)\n",
        "                    gpu_mae = cp.mean(cp.abs(residuals))\n",
        "                    gpu_std = cp.std(residuals)\n",
        "\n",
        "                    # Confidence calculation\n",
        "                    confidence_weights = cp.asarray([0.4, 0.3, 0.3], dtype=cp.float32)\n",
        "                    gpu_aic = cp.asarray(self.model.aic, dtype=cp.float32)\n",
        "                    gpu_rsquared = cp.asarray(self.model.rsquared, dtype=cp.float32)\n",
        "\n",
        "                    # Normalize metrics\n",
        "                    gpu_aic_norm = 1 / (1 + cp.exp(gpu_aic/1000))\n",
        "                    gpu_residual_norm = 1 / (1 + gpu_std)\n",
        "\n",
        "                    # Calculate confidence score\n",
        "                    confidence_inputs = cp.array([\n",
        "                        gpu_rsquared,\n",
        "                        gpu_residual_norm,\n",
        "                        gpu_aic_norm\n",
        "                    ])\n",
        "                    gpu_model_confidence = cp.sum(confidence_weights * confidence_inputs)\n",
        "\n",
        "                    # Get prediction intervals\n",
        "                    pred_intervals = forecast_results.conf_int(alpha=0.05)\n",
        "\n",
        "                    # Prepare metrics with minimal transfers\n",
        "                    metrics = {\n",
        "                        'r2': float(cp.asnumpy(gpu_rsquared)),\n",
        "                        'aic': float(cp.asnumpy(gpu_aic)),\n",
        "                        'bic': float(self.model.bic),\n",
        "                        'llf': float(self.model.llf),\n",
        "                        'mse': float(cp.asnumpy(gpu_mse)),\n",
        "                        'mae': float(cp.asnumpy(gpu_mae)),\n",
        "                        'residual_std': float(cp.asnumpy(gpu_std)),\n",
        "                        'forecast_variances': cp.asnumpy(gpu_variances),\n",
        "                        'forecast_covariances': cp.asnumpy(gpu_covariance),\n",
        "                        'model_confidence': float(cp.asnumpy(gpu_model_confidence)),\n",
        "                        'prediction_intervals': pred_intervals\n",
        "                    }\n",
        "\n",
        "                    return metrics\n",
        "\n",
        "                except cp.cuda.memory.OutOfMemoryError:\n",
        "                    self._cleanup_gpu_memory()\n",
        "                    # Return empty metrics if we can't recover\n",
        "                    return self._get_empty_metrics()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating regression metrics: {str(e)}\")\n",
        "            self._cleanup_gpu_memory()\n",
        "            return self._get_empty_metrics()\n",
        "\n",
        "    def _get_empty_metrics(self) -> Dict:\n",
        "        \"\"\"Return empty metrics dictionary\"\"\"\n",
        "        return {\n",
        "            'r2': cp.nan,\n",
        "            'aic': cp.nan,\n",
        "            'bic': cp.nan,\n",
        "            'llf': cp.nan,\n",
        "            'mse': cp.nan,\n",
        "            'mae': cp.nan,\n",
        "            'residual_std': cp.nan,\n",
        "            'forecast_variances': None,\n",
        "            'forecast_covariances': None,\n",
        "            'model_confidence': cp.nan,\n",
        "            'prediction_intervals': None\n",
        "        }\n",
        "\n",
        "    def __del__(self):\n",
        "        \"\"\"Cleanup when object is destroyed\"\"\"\n",
        "        self._cleanup_gpu_memory()\n",
        "\n",
        "\n",
        "class PositionSizer:\n",
        "    def __init__(self,\n",
        "                 base_kelly_fraction: float = 0.25,\n",
        "                 max_position_size: float = 0.15,\n",
        "                 min_position_size: float = 0.02,\n",
        "                 transaction_cost: float = 0.0003,\n",
        "                 session_cutoff: str = \"15:15:00\"):\n",
        "        \"\"\"GPU-optimized position sizing with intraday risk management\"\"\"\n",
        "        # Initialize parameters on GPU\n",
        "        self.base_kelly = cp.asarray(base_kelly_fraction, dtype=cp.float32)\n",
        "        self.max_size = cp.asarray(max_position_size, dtype=cp.float32)\n",
        "        self.min_size = cp.asarray(min_position_size, dtype=cp.float32)\n",
        "        self.transaction_cost = cp.asarray(transaction_cost, dtype=cp.float32)\n",
        "        self.session_cutoff = pd.Timedelta(session_cutoff)\n",
        "\n",
        "        # Initialize rolling volatility window on GPU\n",
        "        self.volatility_window = cp.zeros(20, dtype=cp.float32)  # 20-period rolling vol\n",
        "        self.atr_window = cp.zeros(14, dtype=cp.float32)         # 14-period ATR\n",
        "\n",
        "        # Risk adjustment parameters\n",
        "        self.volatility_scalar = cp.ones(1, dtype=cp.float32)\n",
        "        self.time_decay_scalar = cp.ones(1, dtype=cp.float32)\n",
        "        self.drawdown_scalar = cp.ones(1, dtype=cp.float32)\n",
        "\n",
        "    def _calculate_time_decay(self, current_time: pd.Timestamp) -> cp.ndarray:\n",
        "        \"\"\"Time-based position scaling on GPU\"\"\"\n",
        "        time_left = self.session_cutoff - current_time\n",
        "        hours_left = time_left.total_seconds() / 3600\n",
        "\n",
        "        # Exponential decay in last 2 hours\n",
        "        decay_factor = cp.where(\n",
        "            hours_left < 2,\n",
        "            cp.exp(-2.5 * (2 - hours_left)),\n",
        "            cp.asarray(1.0, dtype=cp.float32)\n",
        "        )\n",
        "        return cp.clip(decay_factor, 0.1, 1.0)\n",
        "\n",
        "    def _update_volatility(self, ohlc_data: Dict[str, cp.ndarray]) -> None:\n",
        "        \"\"\"Update volatility metrics using GPU-accelerated calculations\"\"\"\n",
        "        # Calculate true range\n",
        "        high_low = ohlc_data['high'] - ohlc_data['low']\n",
        "        high_close = cp.abs(ohlc_data['high'] - ohlc_data['close'].shift(1))\n",
        "        low_close = cp.abs(ohlc_data['low'] - ohlc_data['close'].shift(1))\n",
        "        true_range = cp.maximum(cp.maximum(high_low, high_close), low_close)\n",
        "\n",
        "        # Update ATR with smoothing\n",
        "        self.atr_window = cp.roll(self.atr_window, -1)\n",
        "        self.atr_window[-1] = 0.8*self.atr_window[-2] + 0.2*true_range[-1] if len(self.atr_window) > 1 else true_range[-1]\n",
        "\n",
        "        # Update volatility window with returns\n",
        "        returns = cp.log(ohlc_data['close'][-20:]/ohlc_data['close'].shift(1)[-20:])\n",
        "        self.volatility_window = cp.roll(self.volatility_window, -1)\n",
        "        self.volatility_window[-1] = cp.std(returns)\n",
        "\n",
        "    def _calculate_volatility_scalar(self) -> cp.ndarray:\n",
        "        \"\"\"Volatility-adjusted position scaling\"\"\"\n",
        "        atr_ratio = self.atr_window[-1] / cp.mean(self.atr_window)\n",
        "        vol_ratio = self.volatility_window[-1] / cp.mean(self.volatility_window)\n",
        "\n",
        "        # Combine volatility measures\n",
        "        combined_vol = 0.7*vol_ratio + 0.3*atr_ratio\n",
        "        return cp.clip(1.0 / combined_vol, 0.33, 3.0)\n",
        "\n",
        "    def _calculate_kelly_size(self,\n",
        "                            win_prob: cp.ndarray,\n",
        "                            risk_reward: cp.ndarray,\n",
        "                            confidence: cp.ndarray) -> cp.ndarray:\n",
        "        \"\"\"Modified Kelly Criterion with transaction costs\"\"\"\n",
        "        # Adjust win probability with confidence\n",
        "        adj_win_prob = 0.5 + (win_prob - 0.5) * confidence\n",
        "\n",
        "        # Kelly formula with cost adjustment\n",
        "        numerator = adj_win_prob*risk_reward - (1 - adj_win_prob)\n",
        "        denominator = risk_reward\n",
        "        raw_kelly = numerator / denominator - self.transaction_cost\n",
        "\n",
        "        return self.base_kelly * cp.clip(raw_kelly, 0.0, 1.0)\n",
        "\n",
        "    def calculate_position_size(self,\n",
        "                              signal: str,\n",
        "                              confidence: float,\n",
        "                              current_time: pd.Timestamp,\n",
        "                              ohlc_data: Dict[str, cp.ndarray],\n",
        "                              portfolio_value: float,\n",
        "                              current_drawdown: float) -> Tuple[float, Dict]:\n",
        "        \"\"\"Calculate optimal position size with GPU acceleration\"\"\"\n",
        "        try:\n",
        "            # Convert inputs to GPU arrays\n",
        "            confidence_gpu = cp.asarray(confidence, dtype=cp.float32)\n",
        "            drawdown_gpu = cp.asarray(current_drawdown, dtype=cp.float32)\n",
        "\n",
        "            # Update volatility metrics\n",
        "            self._update_volatility({k: cp.asarray(v) for k, v in ohlc_data.items()})\n",
        "\n",
        "            # Calculate risk scalars on GPU\n",
        "            self.volatility_scalar = self._calculate_volatility_scalar()\n",
        "            self.time_decay_scalar = self._calculate_time_decay(current_time)\n",
        "            self.drawdown_scalar = 1.0 - cp.clip(drawdown_gpu/0.2, 0.0, 0.5)  # Reduce sizing at >20% drawdown\n",
        "\n",
        "            # Calculate position components\n",
        "            win_prob = confidence_gpu * 0.8 + 0.2  # Map confidence to [0.2-1.0] win probability\n",
        "            risk_reward = cp.asarray(2.0, dtype=cp.float32)  # Fixed 2:1 risk-reward ratio\n",
        "\n",
        "            # Calculate base Kelly size\n",
        "            raw_size = self._calculate_kelly_size(win_prob, risk_reward, confidence_gpu)\n",
        "\n",
        "            # Apply risk scalars\n",
        "            adj_size = raw_size * self.volatility_scalar * self.time_decay_scalar * self.drawdown_scalar\n",
        "\n",
        "            # Convert to percentage of portfolio\n",
        "            position_pct = cp.clip(adj_size, self.min_size, self.max_size).get()\n",
        "            position_value = position_pct * portfolio_value\n",
        "\n",
        "            # Prepare detailed metrics\n",
        "            metrics = {\n",
        "                'position_size_pct': float(position_pct),\n",
        "                'volatility_scalar': float(self.volatility_scalar.get()),\n",
        "                'time_decay_scalar': float(self.time_decay_scalar.get()),\n",
        "                'drawdown_scalar': float(self.drawdown_scalar.get()),\n",
        "                'raw_kelly_size': float(raw_size.get()),\n",
        "                'current_atr': float(self.atr_window[-1].get()),\n",
        "                'current_volatility': float(self.volatility_window[-1].get())\n",
        "            }\n",
        "\n",
        "            return position_value, metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Position sizing error: {str(e)}\")\n",
        "            return 0.0, {}\n",
        "\n",
        "\n",
        "class DecisionLayer:\n",
        "    def __init__(self, transaction_cost: float = 0.0001, risk_aversion: float = 1.645):\n",
        "        \"\"\"Initialize Decision Layer with GPU-optimized parameters\"\"\"\n",
        "        # Move constants to GPU at initialization\n",
        "        self.position_sizer = PositionSizer()\n",
        "        self.transaction_cost = cp.asarray(transaction_cost)\n",
        "        self.risk_aversion = cp.asarray(risk_aversion)\n",
        "\n",
        "        # Store horizon weights on GPU\n",
        "        self.horizon_weights = {\n",
        "            1: cp.asarray(0.5),  # 30-min forecast\n",
        "            2: cp.asarray(0.3),  # 60-min forecast\n",
        "            3: cp.asarray(0.2)   # 90-min forecast\n",
        "        }\n",
        "\n",
        "        # Move threshold parameters to GPU\n",
        "        self.alpha = cp.asarray(0.6)  # R² weight\n",
        "        self.beta = cp.asarray(0.4)   # AIC weight\n",
        "        self.gamma = cp.asarray(0.1)  # Model confidence scaling\n",
        "        self.min_probability = cp.asarray(0.7)\n",
        "        self.base_risk_aversion = cp.asarray(1.645)\n",
        "\n",
        "        # Precompute weight vector for efficiency\n",
        "        self.weight_vector = cp.array([self.horizon_weights[h] for h in sorted(self.horizon_weights.keys())])\n",
        "\n",
        "    def compute_weighted_forecast(self, predictions: Dict[int, cp.ndarray],\n",
        "                                variances: Dict[int, cp.ndarray],\n",
        "                                covariance_matrix: cp.ndarray) -> Tuple[cp.ndarray, cp.ndarray]:\n",
        "        \"\"\"Compute weighted forecast and variance on GPU\"\"\"\n",
        "        # Convert predictions to GPU array\n",
        "        pred_array = cp.array([predictions[h] for h in sorted(predictions.keys())])\n",
        "\n",
        "        # Compute weighted forecast using vectorized operations\n",
        "        weighted_forecast = cp.sum(self.weight_vector * pred_array)\n",
        "\n",
        "        # Compute total variance using matrix operations on GPU\n",
        "        total_variance = cp.sum(\n",
        "            cp.outer(self.weight_vector, self.weight_vector) * covariance_matrix\n",
        "        )\n",
        "\n",
        "        return weighted_forecast, total_variance\n",
        "\n",
        "    def compute_expected_profit(self, current_price: cp.ndarray,\n",
        "                              weighted_forecast: cp.ndarray,\n",
        "                              total_variance: cp.ndarray,\n",
        "                              model_confidence: cp.ndarray,\n",
        "                              action: str = 'buy') -> cp.ndarray:\n",
        "        \"\"\"Compute risk-adjusted expected profit on GPU\"\"\"\n",
        "        std_dev = cp.sqrt(total_variance)\n",
        "        current_price_gpu = cp.asarray(current_price)\n",
        "\n",
        "        if action == 'buy':\n",
        "            model_gain = weighted_forecast - current_price_gpu\n",
        "            transaction_costs = 2 * self.transaction_cost * current_price_gpu\n",
        "        else:  # sell\n",
        "            model_gain = current_price_gpu - weighted_forecast\n",
        "            transaction_costs = self.transaction_cost * current_price_gpu\n",
        "\n",
        "        risk_penalty = self.risk_aversion * std_dev\n",
        "        confidence_boost = self.gamma * model_confidence\n",
        "\n",
        "        return model_gain - transaction_costs - risk_penalty + confidence_boost\n",
        "\n",
        "    def compute_trade_probability(self, current_price: cp.ndarray,\n",
        "                                weighted_forecast: cp.ndarray,\n",
        "                                total_variance: cp.ndarray,\n",
        "                                action: str = 'buy') -> cp.ndarray:\n",
        "        \"\"\"Compute trade probability on GPU\"\"\"\n",
        "        std_dev = cp.sqrt(total_variance)\n",
        "        current_price_gpu = cp.asarray(current_price)\n",
        "\n",
        "        if action == 'buy':\n",
        "            tc = 2 * self.transaction_cost * current_price_gpu\n",
        "            z_score = (weighted_forecast - current_price_gpu - tc) / std_dev\n",
        "            prob = 1 - 0.5 * (1 + cp.erf(z_score / cp.sqrt(2.0)))  # GPU-based normal CDF\n",
        "        else:  # sell\n",
        "            tc = self.transaction_cost * current_price_gpu\n",
        "            z_score = (current_price_gpu - tc - weighted_forecast) / std_dev\n",
        "            prob = 0.5 * (1 + cp.erf(z_score / cp.sqrt(2.0)))  # GPU-based normal CDF\n",
        "\n",
        "        return prob\n",
        "\n",
        "    def adjust_parameters(self, market_volatility: cp.ndarray,\n",
        "                         rolling_sharpe: cp.ndarray,\n",
        "                         window_volatility: cp.ndarray):\n",
        "        \"\"\"Dynamically adjust decision parameters on GPU\"\"\"\n",
        "        # Move inputs to GPU if needed\n",
        "        market_vol_gpu = cp.asarray(market_volatility)\n",
        "        window_vol_gpu = cp.asarray(window_volatility)\n",
        "        rolling_sharpe_gpu = cp.asarray(rolling_sharpe)\n",
        "\n",
        "        # Compute volatility scalar on GPU\n",
        "        volatility_scalar = market_vol_gpu / window_vol_gpu\n",
        "        self.risk_aversion = self.base_risk_aversion * (\n",
        "            1 + cp.clip(volatility_scalar - 1, -0.5, 1.0)\n",
        "        )\n",
        "\n",
        "        # Adjust threshold parameters based on performance\n",
        "        self.alpha = cp.where(\n",
        "            rolling_sharpe_gpu > 1.5,\n",
        "            cp.asarray(0.5),  # More aggressive\n",
        "            cp.where(\n",
        "                rolling_sharpe_gpu < 0.5,\n",
        "                cp.asarray(0.7),  # More conservative\n",
        "                self.alpha\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.beta = cp.where(\n",
        "            rolling_sharpe_gpu > 1.5,\n",
        "            cp.asarray(0.3),\n",
        "            cp.where(\n",
        "                rolling_sharpe_gpu < 0.5,\n",
        "                cp.asarray(0.5),\n",
        "                self.beta\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.min_probability = cp.where(\n",
        "            rolling_sharpe_gpu > 1.5,\n",
        "            cp.asarray(0.65),\n",
        "            cp.where(\n",
        "                rolling_sharpe_gpu < 0.5,\n",
        "                cp.asarray(0.75),\n",
        "                self.min_probability\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def generate_trading_signal(self,\n",
        "                              current_price: float,\n",
        "                              predictions: Dict[int, float],\n",
        "                              model_metrics: Dict,\n",
        "                              market_state: Dict,\n",
        "                              portfolio_state: Dict) -> Tuple[str, float, Dict]:\n",
        "        \"\"\"Generate trading signal with GPU-optimized calculations\"\"\"\n",
        "        try:\n",
        "            # Move all inputs to GPU\n",
        "            current_price_gpu = cp.asarray(current_price)\n",
        "            predictions_gpu = {k: cp.asarray(v) for k, v in predictions.items()}\n",
        "            variances_gpu = cp.asarray(model_metrics['forecast_variances'])\n",
        "            covariance_gpu = cp.asarray(model_metrics['forecast_covariances'])\n",
        "            model_confidence_gpu = cp.asarray(model_metrics['model_confidence'])\n",
        "\n",
        "            # Update parameters based on market conditions\n",
        "            self.adjust_parameters(\n",
        "                cp.asarray(market_state.get('market_volatility', 0)),\n",
        "                cp.asarray(market_state.get('rolling_sharpe', 1.0)),\n",
        "                cp.asarray(market_state.get('window_volatility', 0))\n",
        "            )\n",
        "\n",
        "            # Compute weighted forecast and uncertainty on GPU\n",
        "            weighted_forecast, total_variance = self.compute_weighted_forecast(\n",
        "                predictions_gpu, variances_gpu, covariance_gpu\n",
        "            )\n",
        "\n",
        "            # Compute threshold on GPU\n",
        "            threshold = (self.alpha * cp.asarray(model_metrics['r2']) +\n",
        "                       self.beta * (1 / (1 + cp.exp(cp.asarray(model_metrics['aic'])/1000))))\n",
        "\n",
        "            # Compute profits and probabilities on GPU\n",
        "            buy_profit = self.compute_expected_profit(\n",
        "                current_price_gpu, weighted_forecast, total_variance,\n",
        "                model_confidence_gpu, 'buy'\n",
        "            )\n",
        "\n",
        "            sell_profit = self.compute_expected_profit(\n",
        "                current_price_gpu, weighted_forecast, total_variance,\n",
        "                model_confidence_gpu, 'sell'\n",
        "            )\n",
        "\n",
        "            buy_prob = self.compute_trade_probability(\n",
        "                current_price_gpu, weighted_forecast, total_variance, 'buy'\n",
        "            )\n",
        "\n",
        "            sell_prob = self.compute_trade_probability(\n",
        "                current_price_gpu, weighted_forecast, total_variance, 'sell'\n",
        "            )\n",
        "\n",
        "            # Generate signal (logic on GPU)\n",
        "            signal = 'hold'\n",
        "            confidence_score = cp.asarray(0.0)\n",
        "\n",
        "            if (buy_profit > threshold).get() and (buy_prob > self.min_probability).get():\n",
        "                signal = 'buy'\n",
        "                confidence_score = buy_prob * (buy_profit / threshold)\n",
        "            elif (sell_profit > threshold).get() and (sell_prob > self.min_probability).get():\n",
        "                signal = 'sell'\n",
        "                confidence_score = sell_prob * (sell_profit / threshold)\n",
        "\n",
        "            # Transfer final results back to CPU only once\n",
        "            detailed_metrics = {\n",
        "                'weighted_forecast': float(cp.asnumpy(weighted_forecast)),\n",
        "                'forecast_std': float(cp.asnumpy(cp.sqrt(total_variance))),\n",
        "                'threshold': float(cp.asnumpy(threshold)),\n",
        "                'buy_profit': float(cp.asnumpy(buy_profit)),\n",
        "                'sell_profit': float(cp.asnumpy(sell_profit)),\n",
        "                'buy_probability': float(cp.asnumpy(buy_prob)),\n",
        "                'sell_probability': float(cp.asnumpy(sell_prob)),\n",
        "                'model_confidence': float(cp.asnumpy(model_confidence_gpu)),\n",
        "                'risk_aversion': float(cp.asnumpy(self.risk_aversion)),\n",
        "                'confidence_score': float(cp.asnumpy(confidence_score))\n",
        "            }\n",
        "            position_size, size_metrics = self.position_sizer.calculate_position_size(\n",
        "            signal=signal,\n",
        "            confidence=float(cp.asnumpy(confidence_score)),\n",
        "            current_time=market_state['timestamp'],\n",
        "            ohlc_data=market_state['ohlc'],\n",
        "            portfolio_value=portfolio_state['value'],\n",
        "            current_drawdown=portfolio_state['drawdown']\n",
        "            )\n",
        "            detailed_metrics.update(size_metrics)\n",
        "            detailed_metrics['position_size'] = position_size\n",
        "\n",
        "            return signal, float(cp.asnumpy(confidence_score)), detailed_metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating trading signal: {str(e)}\")\n",
        "            return 'hold', 0.0, {}\n",
        "\n",
        "def calculate_trading_performance(metrics_df: pd.DataFrame, signals_df: pd.DataFrame) -> Dict:\n",
        "    \"\"\"Calculate performance metrics for trading signals with GPU optimization\"\"\"\n",
        "    try:\n",
        "        # Initialize empty performance dict\n",
        "        performance = {}\n",
        "\n",
        "        # Move signal data to GPU\n",
        "        signals_gpu = cp.array(signals_df['signal'].values != 'hold')\n",
        "        if not cp.any(signals_gpu):\n",
        "            return performance\n",
        "\n",
        "        # Get trade indices and move relevant data to GPU\n",
        "        trade_mask = signals_gpu.get()  # Single transfer back to CPU for indexing\n",
        "\n",
        "        # Move all required data to GPU at once\n",
        "        returns_gpu = cp.array(metrics_df.set_index('timestamp').loc[signals_df.index[trade_mask], 'actual_return'].values)\n",
        "        signals_trade_gpu = cp.array(signals_df.loc[signals_df.index[trade_mask], 'signal'].values == 'buy')\n",
        "        confidence_gpu = cp.array(signals_df.loc[signals_df.index[trade_mask], 'confidence'].values)\n",
        "\n",
        "        # Calculate adjusted returns on GPU\n",
        "        adjusted_returns_gpu = cp.where(signals_trade_gpu, returns_gpu, -returns_gpu)\n",
        "\n",
        "        # Calculate metrics on GPU\n",
        "        total_trades = int(cp.sum(signals_gpu).get())\n",
        "        winning_trades = int(cp.sum(adjusted_returns_gpu > 0).get())\n",
        "\n",
        "        # Calculate average return and std on GPU\n",
        "        avg_return = float(cp.mean(adjusted_returns_gpu).get())\n",
        "        return_std = float(cp.std(adjusted_returns_gpu).get())\n",
        "\n",
        "        # Calculate Sharpe ratio on GPU\n",
        "        sharpe_ratio = 0.0\n",
        "        if total_trades > 1:\n",
        "            annualization_factor = cp.sqrt(cp.array(252.0))\n",
        "            sharpe_ratio = float((avg_return / return_std * annualization_factor).get())\n",
        "\n",
        "        # Calculate average confidence on GPU\n",
        "        avg_confidence = float(cp.mean(confidence_gpu).get())\n",
        "\n",
        "        # Update performance metrics (single transfer back to CPU)\n",
        "        performance.update({\n",
        "            'total_trades': total_trades,\n",
        "            'winning_trades': winning_trades,\n",
        "            'average_return': avg_return,\n",
        "            'return_std': return_std,\n",
        "            'sharpe_ratio': sharpe_ratio,\n",
        "            'avg_confidence': avg_confidence,\n",
        "\n",
        "            # Additional GPU-calculated metrics\n",
        "            'win_rate': winning_trades / total_trades if total_trades > 0 else 0.0,\n",
        "            'profit_factor': float(cp.sum(cp.where(adjusted_returns_gpu > 0, adjusted_returns_gpu, 0)).get() /\n",
        "                                 abs(float(cp.sum(cp.where(adjusted_returns_gpu < 0, adjusted_returns_gpu, 0)).get()))\n",
        "                                 ) if total_trades > 0 else 0.0,\n",
        "            'max_drawdown': float(cp.min(cp.minimum.accumulate(adjusted_returns_gpu)).get()),\n",
        "            'volatility_annual': float(return_std * cp.sqrt(cp.array(252.0)).get()) if return_std else 0.0\n",
        "        })\n",
        "\n",
        "        # Clean up GPU memory\n",
        "        del signals_gpu, returns_gpu, signals_trade_gpu, confidence_gpu, adjusted_returns_gpu\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "        return performance\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating trading performance: {str(e)}\")\n",
        "        # Clean up GPU memory in case of error\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "        return {}\n",
        "\n",
        "\n",
        "\n",
        "def walk_forward_analysis_with_decisions(df: pd.DataFrame):\n",
        "\n",
        "    wandb.init(project=\"gpu_parallel_forecast\", config=CONFIG)\n",
        "\n",
        "    try:\n",
        "        # Move entire dataframe to GPU at start\n",
        "        df_gpu = {\n",
        "            'close': cp.asarray(df['close'].values, dtype=cp.float32),\n",
        "            'returns': cp.asarray(df['returns'].values, dtype=cp.float32)\n",
        "        }\n",
        "\n",
        "        # Calculate indices\n",
        "        total_periods = len(df)\n",
        "        six_months_periods = period_calculator(6)\n",
        "        last_index = total_periods - 1\n",
        "        decision_start_index = max(0, last_index - six_months_periods)\n",
        "        max_horizon = max(CONFIG[\"forecast_horizons\"])\n",
        "        steps = CONFIG[\"step_size_periods\"]\n",
        "\n",
        "        # Initialize GPU arrays for predictions with proper dtype\n",
        "        predictions = {\n",
        "            model: {h: cp.full(total_periods, cp.nan, dtype=cp.float32)\n",
        "                   for h in CONFIG[\"forecast_horizons\"]}\n",
        "            for model in CONFIG[\"models\"]\n",
        "        }\n",
        "\n",
        "        actuals = {\n",
        "            h: cp.full(total_periods, cp.nan, dtype=cp.float32)\n",
        "            for h in CONFIG[\"forecast_horizons\"]\n",
        "        }\n",
        "\n",
        "        # Pre-allocate GPU arrays for market state calculations\n",
        "        rolling_window = 500\n",
        "        market_state_gpu = {\n",
        "            'returns_buffer': cp.zeros(rolling_window, dtype=cp.float32),\n",
        "            'volatility_window': cp.zeros(20, dtype=cp.float32)\n",
        "        }\n",
        "\n",
        "        # Initialize trading signals and metrics\n",
        "        trading_signals = pd.DataFrame(index=df.index[decision_start_index:],\n",
        "                                     columns=['signal', 'confidence', 'model_used'])\n",
        "        trading_metrics = []\n",
        "\n",
        "        # Initialize decision layer\n",
        "        decision_layer = DecisionLayer()\n",
        "\n",
        "        def train_and_forecast_with_metrics(config: Dict, data_gpu: cp.ndarray, steps: int) -> Tuple[cp.ndarray, Dict]:\n",
        "            \"\"\"GPU-optimized training and forecasting\"\"\"\n",
        "            model = BaseModel(config)\n",
        "            success = model.train(data_gpu)\n",
        "            if success:\n",
        "                forecast = model.forecast(steps)\n",
        "                metrics = model.get_regression_metrics()\n",
        "                return forecast, metrics\n",
        "            return cp.full(steps, cp.nan, dtype=cp.float32), None\n",
        "\n",
        "        def align_and_store_forecasts(forecasts: List[cp.ndarray],\n",
        "                                    current_index: int,\n",
        "                                    effective_steps: int) -> None:\n",
        "            \"\"\"Align and store forecasts with proper horizon handling\"\"\"\n",
        "            for (model_name, _), fcst in zip(CONFIG[\"models\"].items(), forecasts):\n",
        "                if fcst is None or cp.all(cp.isnan(fcst)):\n",
        "                    continue\n",
        "\n",
        "                for h in CONFIG[\"forecast_horizons\"]:\n",
        "                    if h <= len(fcst):\n",
        "                        # Calculate proper forecast alignment indices\n",
        "                        forecast_start = current_index\n",
        "                        valid_steps = min(effective_steps, len(fcst)-h+1)\n",
        "                        forecast_end = forecast_start + valid_steps\n",
        "\n",
        "                        if forecast_end <= forecast_start:\n",
        "                            continue\n",
        "\n",
        "                        # Use direct slicing instead of tile for more efficient memory usage\n",
        "                        predictions[model_name][h][forecast_start:forecast_end] = fcst[h-1:h-1+valid_steps]\n",
        "\n",
        "                        # Update actuals with efficient slicing\n",
        "                        actual_start = forecast_start + h - 1\n",
        "                        actual_end = actual_start + valid_steps\n",
        "                        if actual_end <= total_periods:\n",
        "                            actuals[h][forecast_start:forecast_end] = df_gpu['returns'][actual_start:actual_end]\n",
        "\n",
        "        # Batch process training data\n",
        "        i = CONFIG[\"initial_train_periods\"]\n",
        "        with tqdm(total=total_periods, desc=\"Forecasting Progress\") as pbar:\n",
        "            while i <= total_periods - max_horizon - 1:\n",
        "                effective_steps = min(steps, total_periods - i - max_horizon)\n",
        "                if effective_steps <= 0:\n",
        "                    break\n",
        "\n",
        "                # Prepare training data on GPU\n",
        "                train_start = max(0, i - CONFIG[\"rolling_window_periods\"])\n",
        "                train_data_gpu = cp.asarray(df_gpu['returns'][train_start:i], dtype=cp.float32)\n",
        "\n",
        "                # Process models in parallel with GPU data\n",
        "                model_results = Parallel(n_jobs=CONFIG[\"n_jobs\"])(\n",
        "                    delayed(train_and_forecast_with_metrics)(config, train_data_gpu, max_horizon)\n",
        "                    for config in CONFIG[\"models\"].values()\n",
        "                )\n",
        "\n",
        "                forecasts, metrics_list = zip(*model_results)\n",
        "\n",
        "                # Update predictions on GPU\n",
        "                for (model_name, _), fcst in zip(CONFIG[\"models\"].items(), forecasts):\n",
        "                    for h in CONFIG[\"forecast_horizons\"]:\n",
        "                        if h <= len(fcst):\n",
        "                            predictions[model_name][h][i:i+effective_steps] = cp.tile(fcst[h-1], effective_steps)\n",
        "\n",
        "                # Update actuals on GPU\n",
        "                for h in CONFIG[\"forecast_horizons\"]:\n",
        "                    actual_start = i + h\n",
        "                    actual_end = actual_start + effective_steps\n",
        "                    actuals[h][i:i+effective_steps] = df_gpu['returns'][actual_start:actual_end]\n",
        "\n",
        "                # Apply decision layer for last 6 months\n",
        "                if i >= decision_start_index:\n",
        "                    # Compute market state on GPU\n",
        "                    window_start = max(0, i-500)\n",
        "                    market_state_gpu['returns_buffer'] = df_gpu['returns'][window_start:i]\n",
        "                    market_state_gpu['volatility_window'] = df_gpu['returns'][i-20:i]\n",
        "\n",
        "                    market_state = {\n",
        "                        'ohlc': {\n",
        "                          'open': df_gpu['open'][i-20:i],\n",
        "                          'high': df_gpu['high'][i-20:i],\n",
        "                          'low': df_gpu['low'][i-20:i],\n",
        "                          'close': df_gpu['close'][i-20:i]\n",
        "                      },\n",
        "                        'market_volatility': float(cp.std(market_state_gpu['returns_buffer']).get()),\n",
        "                        'rolling_sharpe': float((cp.mean(market_state_gpu['returns_buffer']) /\n",
        "                                              cp.std(market_state_gpu['returns_buffer']) *\n",
        "                                              cp.sqrt(cp.array(252.0))).get()),\n",
        "                        'window_volatility': float(cp.std(market_state_gpu['volatility_window']).get())\n",
        "                    }\n",
        "\n",
        "                    # Find best model on GPU\n",
        "                    if metrics_list:\n",
        "                        model_performances = {\n",
        "                            name: metrics['model_confidence'] if metrics else cp.nan\n",
        "                            for (name, _), metrics in zip(CONFIG[\"models\"].items(), metrics_list)\n",
        "                        }\n",
        "\n",
        "                        valid_models = {k: v for k, v in model_performances.items() if not np.isnan(v)}\n",
        "                        if valid_models:\n",
        "                            best_model = max(valid_models.items(), key=lambda x: x[1])[0]\n",
        "                        else:\n",
        "                            best_model = None  # Handle no valid models\n",
        "                        best_metrics = metrics_list[list(CONFIG[\"models\"].keys()).index(best_model)]\n",
        "\n",
        "                        # Keep predictions on GPU for decision layer\n",
        "                        best_predictions = {\n",
        "                            h: predictions[best_model][h][i]\n",
        "                            for h in CONFIG[\"forecast_horizons\"]\n",
        "                        }\n",
        "\n",
        "                        # Generate trading signal\n",
        "                        signal, confidence, detailed_metrics = decision_layer.generate_trading_signal(\n",
        "                            current_price=float(df_gpu['close'][i].get()),\n",
        "                            predictions=best_predictions,\n",
        "                            model_metrics=best_metrics,\n",
        "                            market_state=market_state\n",
        "                        )\n",
        "\n",
        "                        # Store signal and metrics\n",
        "                        trading_signals.iloc[i-decision_start_index] = [signal, confidence, best_model]\n",
        "                        detailed_metrics.update({\n",
        "                            'timestamp': df.index[i],\n",
        "                            'model_used': best_model,\n",
        "                            'actual_return': float(df_gpu['returns'][i+1].get()) if i+1 < total_periods else cp.nan\n",
        "                        })\n",
        "                        trading_metrics.append(detailed_metrics)\n",
        "\n",
        "                # Log progress\n",
        "                if (i // steps) % 3 == 0:\n",
        "                    log_progress(df, predictions, actuals, i, effective_steps)\n",
        "\n",
        "                pbar.update(effective_steps)\n",
        "                i += effective_steps\n",
        "\n",
        "        # Calculate final metrics\n",
        "        final_metrics = calculate_final_metrics(predictions, actuals)\n",
        "\n",
        "        # Calculate trading performance\n",
        "        if trading_metrics:\n",
        "            trading_df = pd.DataFrame(trading_metrics)\n",
        "            trading_performance = calculate_trading_performance(trading_df, trading_signals)\n",
        "            final_metrics.update(trading_performance)\n",
        "\n",
        "        wandb.log(final_metrics)\n",
        "        wandb.finish()\n",
        "\n",
        "        # Clean up GPU memory\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "        return final_metrics, trading_signals, pd.DataFrame(trading_metrics)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in walk forward analysis: {str(e)}\")\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "        wandb.finish()\n",
        "        return {}, pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "def log_progress(df, predictions, actuals, i, steps):\n",
        "    metrics = {}\n",
        "\n",
        "    # Calculate start and end indices\n",
        "    start = max(0, i - CONFIG[\"plot_sample_size\"])\n",
        "    end = i + steps\n",
        "    dates = df.index[start:end]\n",
        "\n",
        "    # Batch process metrics on GPU for all horizons and models\n",
        "    for h in CONFIG[\"forecast_horizons\"]:\n",
        "        actual_data = actuals[h][start:end]\n",
        "\n",
        "        for model in CONFIG[\"models\"]:\n",
        "            pred_data = predictions[model][h][start:end]\n",
        "            valid_mask = ~cp.isnan(pred_data) & ~cp.isnan(actual_data)\n",
        "\n",
        "            if cp.any(valid_mask):\n",
        "                actual_gpu = actual_data[valid_mask]\n",
        "                pred_gpu = pred_data[valid_mask]\n",
        "\n",
        "                # Calculate metrics on GPU\n",
        "                metrics.update({\n",
        "                    f\"{model}_h{h}_rmse\": float(cp.sqrt(cp.mean((actual_gpu - pred_gpu)**2)).get()),\n",
        "                    f\"{model}_h{h}_mae\": float(cp.mean(cp.abs(actual_gpu - pred_gpu)).get()),\n",
        "                })\n",
        "\n",
        "    # Create plot data only after all GPU computations\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(15, 10))\n",
        "\n",
        "    # Single batch transfer for plotting\n",
        "    plot_data = {\n",
        "        'actuals': {h: cp.asnumpy(actuals[h][start:end]) for h in CONFIG[\"forecast_horizons\"]},\n",
        "        'predictions': {\n",
        "            model: {h: cp.asnumpy(predictions[model][h][start:end])\n",
        "                   for h in CONFIG[\"forecast_horizons\"]}\n",
        "            for model in CONFIG[\"models\"]}\n",
        "    }\n",
        "\n",
        "    # Now plot using the transferred data\n",
        "    for idx, h in enumerate(CONFIG[\"forecast_horizons\"]):\n",
        "        ax = axes[idx]\n",
        "        cpu_actuals = plot_data['actuals'][h]\n",
        "\n",
        "        for model in CONFIG[\"models\"]:\n",
        "            cpu_preds = plot_data['predictions'][model][h]\n",
        "            valid_mask = ~np.isnan(cpu_preds) & ~np.isnan(cpu_actuals)\n",
        "\n",
        "            if np.any(valid_mask):\n",
        "                ax.plot(dates[valid_mask], cpu_preds[valid_mask], alpha=0.7, label=model)\n",
        "\n",
        "        ax.plot(dates, cpu_actuals, 'k-', label='Actual')\n",
        "        ax.set_title(f\"{h*30}-Minute Forecast Horizon\")\n",
        "        ax.legend()\n",
        "\n",
        "    wandb.log({\"forecast_plot\": wandb.Image(fig), **metrics, \"step\": i})\n",
        "    plt.close(fig)\n",
        "\n",
        "def calculate_final_metrics(predictions, actuals):\n",
        "    # Initialize metrics dictionary\n",
        "    final_metrics = {}\n",
        "\n",
        "    # Pre-calculate masks for all models and horizons on GPU\n",
        "    valid_masks = {\n",
        "        model: {\n",
        "            h: ~cp.isnan(predictions[model][h]) & ~cp.isnan(actuals[h])\n",
        "            for h in CONFIG[\"forecast_horizons\"]\n",
        "        }\n",
        "        for model in CONFIG[\"models\"]\n",
        "    }\n",
        "\n",
        "    # Create GPU arrays for metric calculations\n",
        "    for model in CONFIG[\"models\"]:\n",
        "        # Process each model's metrics in batch\n",
        "        model_metrics = {}\n",
        "\n",
        "        for h in CONFIG[\"forecast_horizons\"]:\n",
        "            mask = valid_masks[model][h]\n",
        "\n",
        "            if cp.any(mask):\n",
        "                # Get valid data points on GPU\n",
        "                pred_valid = predictions[model][h][mask]\n",
        "                act_valid = actuals[h][mask]\n",
        "\n",
        "                # Compute all metrics on GPU in batch\n",
        "                diff = act_valid - pred_valid\n",
        "                abs_diff = cp.abs(diff)\n",
        "                squared_diff = diff ** 2\n",
        "\n",
        "                # For directional accuracy\n",
        "                h_val = h  # Use current horizon from loop\n",
        "                act_diff = act_valid[h_val:] - act_valid[:-h_val]\n",
        "                pred_diff = pred_valid[h_val:] - pred_valid[:-h_val]\n",
        "                dir_match = (cp.sign(act_diff) == cp.sign(pred_diff)).astype(float)\n",
        "\n",
        "                # Avoid division by zero in MAPE calculation\n",
        "                mape_mask = act_valid != 0\n",
        "                mape = cp.mean(cp.abs(diff[mape_mask] / act_valid[mape_mask])) * 100 if cp.any(mape_mask) else cp.array(float('nan'))\n",
        "\n",
        "                # Calculate correlation on GPU\n",
        "                act_mean = cp.mean(act_valid)\n",
        "                pred_mean = cp.mean(pred_valid)\n",
        "                covariance = cp.mean((act_valid - act_mean) * (pred_valid - pred_mean))\n",
        "                act_std = cp.sqrt(cp.mean((act_valid - act_mean) ** 2))\n",
        "                pred_std = cp.sqrt(cp.mean((pred_valid - pred_mean) ** 2))\n",
        "                correlation = covariance / (act_std * pred_std) if act_std != 0 and pred_std != 0 else cp.array(0.0)\n",
        "\n",
        "                # Store all metrics in temp dict with single GPU-CPU transfer\n",
        "                metrics_gpu = {\n",
        "                    f\"final_{model}_h{h}_rmse\": cp.sqrt(cp.mean(squared_diff)),\n",
        "                    f\"final_{model}_h{h}_mae\": cp.mean(abs_diff),\n",
        "                    f\"final_{model}_h{h}_corr\": correlation,\n",
        "                    f\"final_{model}_h{h}_mape\": mape,\n",
        "                    f\"final_{model}_h{h}_dir_acc\": cp.mean(dir_match)\n",
        "                }\n",
        "\n",
        "                # Single batch transfer to CPU for all metrics\n",
        "                model_metrics.update({\n",
        "                    key: float(value.get())\n",
        "                    for key, value in metrics_gpu.items()\n",
        "                })\n",
        "\n",
        "        # Update final metrics with batch-processed results\n",
        "        final_metrics.update(model_metrics)\n",
        "\n",
        "    # Release GPU memory explicitly\n",
        "    cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    return final_metrics\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Initialize wandb\n",
        "        wandb.init(project=\"gpu_parallel_forecast\", config=CONFIG)\n",
        "\n",
        "        # Direct data loading with GPU optimization\n",
        "        with cp.cuda.Device(0):\n",
        "            # Read CSV data efficiently\n",
        "            df = pd.read_csv('/content/nifty50_1min_2015_to_2024.csv')\n",
        "\n",
        "            # Convert to datetime and set as index\n",
        "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "            df.set_index('timestamp', inplace=True)\n",
        "\n",
        "            gpu_data = {\n",
        "                'close': cp.asarray(df['close'].values, dtype=cp.float32)\n",
        "            }\n",
        "            # Calculate returns directly on GPU using diff\n",
        "            # This is more efficient than pct_change as it avoids CPU-GPU transfers\n",
        "            gpu_data['returns'] = cp.diff(gpu_data['close']) / gpu_data['close'][:-1]\n",
        "            # Add a NaN at the beginning to match original length\n",
        "            gpu_data['returns'] = cp.concatenate([cp.array([cp.nan]), gpu_data['returns']])\n",
        "            # Take last 16000 samples and create DataFrame\n",
        "            sample_size = 16000\n",
        "            df_analysis = pd.DataFrame({\n",
        "                'close': cp.asnumpy(gpu_data['close'][-sample_size:]),\n",
        "                'returns': cp.asnumpy(gpu_data['returns'][-sample_size:])\n",
        "            }, index=df.index[-sample_size:])\n",
        "\n",
        "            print(f\"\\nAnalysis dataset size: {len(df_analysis):,}\")\n",
        "\n",
        "            # Run walk-forward analysis\n",
        "            results, trading_signals, trading_metrics = walk_forward_analysis_with_decisions(df_analysis)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Main execution failed: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "        wandb.finish()\n"
      ],
      "metadata": {
        "id": "VL3SKj591qA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555,
          "referenced_widgets": [
            "16dbbd53013641d88ee043609aa54256",
            "bf5865398ffb48c6a1dcad213b951e60",
            "6adb92deaf3f4c01ad15258ddb296a42",
            "5d0e47cc51b2486187a4989d8d2343f4",
            "7b46f869969b49f7bff2210ccd03521d",
            "2b07a5fa89484b6ea1395bb0ddad0de8",
            "6810bdb579424f49b519d1fc8b9919c9",
            "a48c84c85efd4b9aa927cc2eeca01b58",
            "33c05b0dc15b439fbe3440babbf9d59f",
            "b9a722765b8b4b378fb516f11779e01f",
            "da328b2722e3478e8a873f02ce80d654"
          ]
        },
        "outputId": "0091982b-3602-4632-fdf8-bec832cbbb4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized dataset size: 30,811\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Forecasting Progress:   0%|          | 0/30811 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16dbbd53013641d88ee043609aa54256"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (252,) (67,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-fc8dc267ecbf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Optimized dataset size: {len(df_30min):,}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwalk_forward_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_30min\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'returns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-fc8dc267ecbf>\u001b[0m in \u001b[0;36mwalk_forward_analysis\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"forecast_horizons\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfcst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                         \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfcst_cp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# Update actuals with correct index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core._ndarray_base.__setitem__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._ndarray_setitem\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._scatter_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy._core._kernel.ufunc.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/internal.pyx\u001b[0m in \u001b[0;36mcupy._core.internal._broadcast_core\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (252,) (67,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/nifty50_1min_2015_to_2024.csv',\n",
        "                    parse_dates=['date'],\n",
        "                    index_col='date',\n",
        "                    usecols=['date', 'close'])\n",
        "\n",
        "    # Resample to 30-min intervals and calculate returns\n",
        "df_30min = df.resample('30T').last().ffill()\n",
        "df_30min['returns'] = df_30min['close'].pct_change().dropna()\n",
        "\n",
        "print(f\"Total periods in dataset: {len(df_30min):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjUHiK9i26-U",
        "outputId": "88b38c51-f35a-4e1f-94e7-8bbafb652bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total periods in dataset: 168,925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-bce14d221314>:8: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  df_30min = df.resample('30T').last().ffill()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "mD_ulfxr63gR",
        "outputId": "43179329-929c-4937-dd6b-2c7cb1b94cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              close\n",
              "date                               \n",
              "2015-01-09 09:15:00+05:30   8292.10\n",
              "2015-01-09 09:16:00+05:30   8288.15\n",
              "2015-01-09 09:17:00+05:30   8293.90\n",
              "2015-01-09 09:18:00+05:30   8300.65\n",
              "2015-01-09 09:19:00+05:30   8301.20\n",
              "...                             ...\n",
              "2024-08-28 15:25:00+05:30  25041.45\n",
              "2024-08-28 15:26:00+05:30  25040.30\n",
              "2024-08-28 15:27:00+05:30  25042.55\n",
              "2024-08-28 15:28:00+05:30  25038.90\n",
              "2024-08-28 15:29:00+05:30  25044.85\n",
              "\n",
              "[890511 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5df555f6-3c34-48f9-b495-538373c3e013\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-01-09 09:15:00+05:30</th>\n",
              "      <td>8292.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-09 09:16:00+05:30</th>\n",
              "      <td>8288.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-09 09:17:00+05:30</th>\n",
              "      <td>8293.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-09 09:18:00+05:30</th>\n",
              "      <td>8300.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-09 09:19:00+05:30</th>\n",
              "      <td>8301.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28 15:25:00+05:30</th>\n",
              "      <td>25041.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28 15:26:00+05:30</th>\n",
              "      <td>25040.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28 15:27:00+05:30</th>\n",
              "      <td>25042.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28 15:28:00+05:30</th>\n",
              "      <td>25038.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28 15:29:00+05:30</th>\n",
              "      <td>25044.85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>890511 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5df555f6-3c34-48f9-b495-538373c3e013')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5df555f6-3c34-48f9-b495-538373c3e013 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5df555f6-3c34-48f9-b495-538373c3e013');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41654752-ad4c-4397-98c6-1dfdf6a0b4e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41654752-ad4c-4397-98c6-1dfdf6a0b4e7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41654752-ad4c-4397-98c6-1dfdf6a0b4e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7fed33e1-f5ce-4939-8c1d-7bd9d6026e7f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7fed33e1-f5ce-4939-8c1d-7bd9d6026e7f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GGVIAmLTHb7L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}