{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1GvMmp1zrvK6KOfhC7Fj3-IDpxk9Zy5uv","authorship_tag":"ABX9TyP2xGrueoJ3ufJH6BgthXiy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from statsmodels.tsa.stattools import adfuller, kpss, acf, pacf\n","from statsmodels.stats.diagnostic import acorr_ljungbox\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import gc\n","import os\n"],"metadata":{"id":"BdeMjDwjX_0L","executionInfo":{"status":"ok","timestamp":1735375485939,"user_tz":-330,"elapsed":570,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oY5SxbtoYifX","executionInfo":{"status":"ok","timestamp":1735375501746,"user_tz":-330,"elapsed":13375,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"}},"outputId":"688970ba-37ea-421b-e8fb-e89ba812da81"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Data Extraction\n","def resample_and_get_periods(csv_path, interval='5T'):\n","   \"\"\"\n","   Load data, resample to 5 min OHLC, perform quality checks, and split into periods\n","\n","   Parameters:\n","   - csv_path: path to CSV file\n","   - interval: resampling interval (default '5T' for 5 minutes)\n","\n","   Returns: Dictionary of quality-checked, resampled dataframes for different periods\n","   \"\"\"\n","   # Load data\n","   def load_and_clean(csv_path):\n","       df = pd.read_csv(csv_path)\n","       df['date'] = pd.to_datetime(df['date'])\n","       return df.set_index('date').sort_index()\n","\n","   # Quality checks\n","   def quality_checks(df, period_name):\n","       issues = []\n","\n","       # Check for missing values\n","       missing = df.isnull().sum()\n","       if missing.any():\n","           issues.append(f\"Missing values found: {missing[missing > 0]}\")\n","\n","       # Check for duplicates\n","       duplicates = df.index.duplicated().sum()\n","       if duplicates:\n","           issues.append(f\"Found {duplicates} duplicate timestamps\")\n","\n","       # Check for price anomalies\n","       price_std = df['close'].std()\n","       price_mean = df['close'].mean()\n","       outliers = df[abs(df['close'] - price_mean) > 3 * price_std]\n","       if not outliers.empty:\n","           issues.append(f\"Found {len(outliers)} potential price outliers\")\n","\n","       # Check for gaps in time series\n","       time_diff = df.index.to_series().diff()\n","       gaps = time_diff[time_diff > pd.Timedelta(minutes=6)]  # More than 6 min gap\n","       if not gaps.empty:\n","           issues.append(f\"Found {len(gaps)} time gaps > 6 minutes\")\n","\n","       # Print issues for this period\n","       if issues:\n","           print(f\"\\nQuality issues in {period_name}:\")\n","           for issue in issues:\n","               print(f\"- {issue}\")\n","\n","       return len(issues) == 0\n","\n","   # Resample to 5 min OHLC\n","   def resample_ohlc(df, interval):\n","       resampled = df.resample(interval).agg({\n","           'open': 'first',\n","           'high': 'max',\n","           'low': 'min',\n","           'close': 'last',\n","           'volume': 'sum'\n","       })\n","       return resampled.dropna()  # Remove any incomplete periods\n","\n","   print(\"Loading and preprocessing data...\")\n","   df = load_and_clean(csv_path)\n","\n","   # Resample full dataset\n","   df_resampled = resample_ohlc(df, interval)\n","\n","   # Get end date\n","   end_date = df_resampled.index.max()\n","\n","   # Define periods and create slices\n","   periods = {\n","       'last_6m': (end_date - pd.DateOffset(months=6), end_date),\n","       'last_to_last_6m': (end_date - pd.DateOffset(months=12),\n","                          end_date - pd.DateOffset(months=6)),\n","       'last_1y': (end_date - pd.DateOffset(years=1), end_date),\n","       'last_to_last_1y': (end_date - pd.DateOffset(years=2),\n","                          end_date - pd.DateOffset(years=1)),\n","       'last_2y': (end_date - pd.DateOffset(years=2), end_date),\n","       'last_to_last_2y': (end_date - pd.DateOffset(years=4),\n","                          end_date - pd.DateOffset(years=2))\n","   }\n","\n","   datasets = {}\n","   print(\"\\nCreating and validating period datasets...\")\n","\n","   for name, (start, end) in periods.items():\n","       # Slice data\n","       period_data = df_resampled[start:end].copy()\n","\n","       # Perform quality checks\n","       is_clean = quality_checks(period_data, name)\n","\n","       # Store data and metadata\n","       datasets[name] = {\n","           'data': period_data,\n","           'metadata': {\n","               'start_date': period_data.index.min(),\n","               'end_date': period_data.index.max(),\n","               'records': len(period_data),\n","               'trading_days': len(set(period_data.index.date)),\n","               'quality_passed': is_clean\n","           }\n","       }\n","\n","   # Print summary\n","   print(\"\\nPeriod Summaries:\")\n","   print(\"=\"*70)\n","   for name, dataset in datasets.items():\n","       meta = dataset['metadata']\n","       print(f\"\\n{name}:\")\n","       print(f\"Date Range: {meta['start_date']} to {meta['end_date']}\")\n","       print(f\"Records: {meta['records']}, Trading Days: {meta['trading_days']}\")\n","       print(f\"Quality Check: {'✓' if meta['quality_passed'] else '✗'}\")\n","\n","   return datasets\n","\n","# Usage\n","REPO_PATH = \"/content/drive/MyDrive/Colab Notebooks/plusEV-\"\n","csv_path = os.path.join(REPO_PATH, \"nifty50_1min_2015_to_2024.csv\")\n","datasets = resample_and_get_periods(csv_path)\n","\n","# # Access data for a period\n","# df0 = datasets['last_6m']['data']\n","# # last_6m_metadata = datasets['last_6m']['metadata']\n","# df0 = datasets['last_to_last_6m']['data']\n","# df0 = datasets['last_1y']['data']\n","# df0 = datasets['last_to_last_1y']['data']\n","# df0 = datasets['last_2y']['data']\n","# df0 = datasets['last_to_last_2y']['data']\n","# df0[\"Return\"] = df0[\"close\"].pct_change()\n","# df0 = df0[\"Return\"].dropna()\n","# df2[\"Return\"] = df2[\"close\"].pct_change()\n","# df2 = df2[\"Return\"].dropna()\n","# df3[\"Return\"] = df3[\"close\"].pct_change()\n","# df3 = df3[\"Return\"].dropna()\n","# df4[\"Return\"] = df4[\"close\"].pct_change()\n","# df4 = df4[\"Return\"].dropna()\n","# df5[\"Return\"] = df5[\"close\"].pct_change()\n","# df5 = df5[\"Return\"].dropna()\n","# df6[\"Return\"] = df6[\"close\"].pct_change()\n","# df6 = df6[\"Return\"].dropna()\n","\n","# print(df1)\n","\n","df_0 = pd.read_csv(csv_path)\n","df_0['date'] = pd.to_datetime(df_0['date'])\n","df_0 = df_0.set_index('date').sort_index()\n","df_0 = df_0.resample('5T').agg({\n","    'open': 'first',\n","    'high': 'max',\n","    'low': 'min',\n","    'close': 'last',\n","    'volume': 'sum'\n","}).fillna(method='ffill')\n","df_0['Return'] = df_0['close'].pct_change()\n","df0 = df_0[\"Return\"].dropna()\n","# midpoint = len(df0) // 2\n","# df0 = df0[midpoint:]\n","# gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gpbladihYvLP","executionInfo":{"status":"ok","timestamp":1735375565533,"user_tz":-330,"elapsed":17573,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"}},"outputId":"1fb7df2c-dbd0-4a8a-ff7d-75545da452d8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading and preprocessing data...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-0b57ef3a0eed>:55: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n","  resampled = df.resample(interval).agg({\n"]},{"output_type":"stream","name":"stdout","text":["\n","Creating and validating period datasets...\n","\n","Quality issues in last_6m:\n","- Found 124 time gaps > 6 minutes\n","\n","Quality issues in last_to_last_6m:\n","- Found 126 time gaps > 6 minutes\n","\n","Quality issues in last_1y:\n","- Found 250 time gaps > 6 minutes\n","\n","Quality issues in last_to_last_1y:\n","- Found 247 time gaps > 6 minutes\n","\n","Quality issues in last_2y:\n","- Found 497 time gaps > 6 minutes\n","\n","Quality issues in last_to_last_2y:\n","- Found 496 time gaps > 6 minutes\n","\n","Period Summaries:\n","======================================================================\n","\n","last_6m:\n","Date Range: 2024-02-28 15:25:00+05:30 to 2024-08-28 15:25:00+05:30\n","Records: 9043, Trading Days: 123\n","Quality Check: ✗\n","\n","last_to_last_6m:\n","Date Range: 2023-08-28 15:25:00+05:30 to 2024-02-28 15:25:00+05:30\n","Records: 9388, Trading Days: 127\n","Quality Check: ✗\n","\n","last_1y:\n","Date Range: 2023-08-28 15:25:00+05:30 to 2024-08-28 15:25:00+05:30\n","Records: 18430, Trading Days: 249\n","Quality Check: ✗\n","\n","last_to_last_1y:\n","Date Range: 2022-08-29 09:15:00+05:30 to 2023-08-28 15:25:00+05:30\n","Records: 18537, Trading Days: 248\n","Quality Check: ✗\n","\n","last_2y:\n","Date Range: 2022-08-29 09:15:00+05:30 to 2024-08-28 15:25:00+05:30\n","Records: 36966, Trading Days: 496\n","Quality Check: ✗\n","\n","last_to_last_2y:\n","Date Range: 2020-08-28 15:25:00+05:30 to 2022-08-26 15:25:00+05:30\n","Records: 37011, Trading Days: 497\n","Quality Check: ✗\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-0b57ef3a0eed>:151: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n","  df_0 = df_0.resample('5T').agg({\n","<ipython-input-4-0b57ef3a0eed>:151: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df_0 = df_0.resample('5T').agg({\n"]}]},{"cell_type":"code","source":["# Add this at the start of your notebook\n","def setup_wandb():\n","    try:\n","        import wandb\n","        # Check if already logged in\n","        if wandb.api.api_key is None:\n","            # Your API key\n","            WANDB_API_KEY = \"641b305133f7d8345e710ecf6c9d83fea7e225f1\"\n","            os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n","\n","        print(\"WandB setup complete!\")\n","        return True\n","    except Exception as e:\n","        print(f\"Error setting up WandB: {str(e)}\")\n","        return False\n","\n","# Use it in your notebook\n","setup_wandb()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-HSor6vVZKCk","executionInfo":{"status":"ok","timestamp":1735375575117,"user_tz":-330,"elapsed":2520,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"}},"outputId":"750aadf8-6134-4439-9ae1-d0e31f29c36e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["WandB setup complete!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"ZG4jeqfbZHaI","executionInfo":{"status":"ok","timestamp":1735375579502,"user_tz":-330,"elapsed":563,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"}},"outputId":"98aaf687-c7b1-46d0-d7d5-3e87eb0c7632"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["date\n","2015-01-09 09:20:00+05:30   -0.000024\n","2015-01-09 09:25:00+05:30   -0.000825\n","2015-01-09 09:30:00+05:30   -0.000681\n","2015-01-09 09:35:00+05:30   -0.000609\n","2015-01-09 09:40:00+05:30    0.000254\n","                               ...   \n","2024-08-28 15:05:00+05:30    0.000102\n","2024-08-28 15:10:00+05:30   -0.000369\n","2024-08-28 15:15:00+05:30   -0.000471\n","2024-08-28 15:20:00+05:30    0.000152\n","2024-08-28 15:25:00+05:30    0.000096\n","Freq: 5min, Name: Return, Length: 1013546, dtype: float64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Return</th>\n","    </tr>\n","    <tr>\n","      <th>date</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2015-01-09 09:20:00+05:30</th>\n","      <td>-0.000024</td>\n","    </tr>\n","    <tr>\n","      <th>2015-01-09 09:25:00+05:30</th>\n","      <td>-0.000825</td>\n","    </tr>\n","    <tr>\n","      <th>2015-01-09 09:30:00+05:30</th>\n","      <td>-0.000681</td>\n","    </tr>\n","    <tr>\n","      <th>2015-01-09 09:35:00+05:30</th>\n","      <td>-0.000609</td>\n","    </tr>\n","    <tr>\n","      <th>2015-01-09 09:40:00+05:30</th>\n","      <td>0.000254</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2024-08-28 15:05:00+05:30</th>\n","      <td>0.000102</td>\n","    </tr>\n","    <tr>\n","      <th>2024-08-28 15:10:00+05:30</th>\n","      <td>-0.000369</td>\n","    </tr>\n","    <tr>\n","      <th>2024-08-28 15:15:00+05:30</th>\n","      <td>-0.000471</td>\n","    </tr>\n","    <tr>\n","      <th>2024-08-28 15:20:00+05:30</th>\n","      <td>0.000152</td>\n","    </tr>\n","    <tr>\n","      <th>2024-08-28 15:25:00+05:30</th>\n","      <td>0.000096</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1013546 rows × 1 columns</p>\n","</div><br><label><b>dtype:</b> float64</label>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from statsmodels.tsa.stattools import acf, pacf\n","import wandb\n","from typing import Dict, List, Tuple\n","from datetime import datetime\n","\n","class TimeSeriesAnalysis:\n","    ACF_KEY: str = 'acf_values'\n","    PACF_KEY: str = 'pacf_values'\n","    ACF_LAGS_KEY: str = 'acf_lags'\n","    PACF_LAGS_KEY: str = 'pacf_lags'\n","\n","    def __init__(self, returns_series, max_lags=200):\n","        self.returns = returns_series\n","        self.max_lags = max_lags\n","\n","        wandb.init(\n","            project=\"Time Series Analysis of Nifty50 5 min ohlc\",\n","            name=f\"ACF_PACF_last_half_data_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n","            group=\"ACF_PACF_analysis\",\n","            config={\n","                \"data_points\": len(returns_series),\n","                \"analysis_type\": \"ACF_PACF\",\n","                \"data_range\": f\"{returns_series.index[0]} to {returns_series.index[-1]}\"\n","            },\n","            tags=[\"ACF\", \"PACF\", \"ARIMA_parameter_calcualtion\"]\n","        )\n","\n","    def compute_acf_pacf(self) -> Dict[str, np.ndarray]:\n","        acf_values = acf(self.returns, nlags=self.max_lags, fft=True)\n","        pacf_values = pacf(self.returns, nlags=self.max_lags, method='yw')\n","\n","        # Create a DataFrame for all computed values\n","        values_df = pd.DataFrame({\n","            'Lag': range(len(acf_values)),\n","            'ACF': acf_values,\n","            'PACF': pacf_values\n","        })\n","\n","        # Log as table instead of individual values\n","        wandb.log({\n","            'ACF_PACF_Values': wandb.Table(dataframe=values_df.round(4))\n","        })\n","\n","        return {\n","            self.ACF_KEY: acf_values,\n","            self.PACF_KEY: pacf_values\n","        }\n","\n","    def plot_acf_pacf(self, acf_values: np.ndarray, pacf_values: np.ndarray, max_display_lags: int = 50) -> None:\n","        try:\n","            plt.figure(figsize=(15, 6))\n","            confidence_interval = 1.96 / np.sqrt(len(self.returns))\n","\n","            # ACF Plot\n","            plt.subplot(1, 2, 1)\n","            plt.stem(range(min(len(acf_values), max_display_lags)),\n","                    acf_values[:max_display_lags])\n","            plt.axhline(y=confidence_interval, color='r', linestyle='--', alpha=0.5)\n","            plt.axhline(y=-confidence_interval, color='r', linestyle='--', alpha=0.5)\n","            plt.fill_between(range(max_display_lags),\n","                            confidence_interval,\n","                            -confidence_interval,\n","                            color='gray',\n","                            alpha=0.2)\n","            plt.title('Autocorrelation Function (ACF)')\n","            plt.xlabel('Lag')\n","            plt.ylabel('ACF')\n","            plt.grid(True, alpha=0.3)\n","\n","            # PACF Plot\n","            plt.subplot(1, 2, 2)\n","            plt.stem(range(min(len(pacf_values), max_display_lags)),\n","                    pacf_values[:max_display_lags])\n","            plt.axhline(y=confidence_interval, color='r', linestyle='--', alpha=0.5)\n","            plt.axhline(y=-confidence_interval, color='r', linestyle='--', alpha=0.5)\n","            plt.fill_between(range(max_display_lags),\n","                            confidence_interval,\n","                            -confidence_interval,\n","                            color='gray',\n","                            alpha=0.2)\n","            plt.title('Partial Autocorrelation Function (PACF)')\n","            plt.xlabel('Lag')\n","            plt.ylabel('PACF')\n","            plt.grid(True, alpha=0.3)\n","\n","            plt.tight_layout()\n","            wandb.log({'ACF_PACF_Plots': wandb.Image(plt)})\n","            plt.close()\n","        finally:\n","            plt.close('all')\n","\n","\n","    def find_significant_lags(self, acf_values, pacf_values, significance_level=0.05):\n","      confidence_interval = 1.96 / np.sqrt(len(self.returns))\n","      significant_acf_lags = [i for i, val in enumerate(acf_values) if abs(val) > confidence_interval]\n","      significant_pacf_lags = [i for i, val in enumerate(pacf_values) if abs(val) > confidence_interval]\n","\n","      # Create detailed DataFrame for ACF significant lags\n","      acf_sig_df = pd.DataFrame({\n","          'Lag': significant_acf_lags,\n","          'ACF_Value': [acf_values[i] for i in significant_acf_lags],\n","          'Normalized_ACF': [abs(acf_values[i]) / confidence_interval for i in significant_acf_lags],\n","          'Is_Highly_Significant': [abs(acf_values[i]) / confidence_interval > 2 for i in significant_acf_lags]\n","      }).sort_values('Normalized_ACF', ascending=False)\n","\n","      # Create detailed DataFrame for PACF significant lags\n","      pacf_sig_df = pd.DataFrame({\n","          'Lag': significant_pacf_lags,\n","          'PACF_Value': [pacf_values[i] for i in significant_pacf_lags],\n","          'Normalized_PACF': [abs(pacf_values[i]) / confidence_interval for i in significant_pacf_lags],\n","          'Is_Highly_Significant': [abs(pacf_values[i]) / confidence_interval > 2 for i in significant_pacf_lags]\n","      }).sort_values('Normalized_PACF', ascending=False)\n","\n","      # Log detailed tables to wandb\n","      wandb.log({\n","          'ACF_Significant_Lags_Detail': wandb.Table(dataframe=acf_sig_df.round(4)),\n","          'PACF_Significant_Lags_Detail': wandb.Table(dataframe=pacf_sig_df.round(4))\n","      })\n","\n","      # Create and log summary table\n","      summary_df = pd.DataFrame({\n","          'Type': ['ACF', 'PACF'],\n","          'Count': [len(significant_acf_lags), len(significant_pacf_lags)],\n","          'Highly_Significant_Count': [sum(acf_sig_df['Is_Highly_Significant']),\n","                                    sum(pacf_sig_df['Is_Highly_Significant'])],\n","          'Max_Normalized_Value': [acf_sig_df['Normalized_ACF'].max() if not acf_sig_df.empty else 0,\n","                                pacf_sig_df['Normalized_PACF'].max() if not pacf_sig_df.empty else 0],\n","          'Significant_Lags_List': [str(significant_acf_lags), str(significant_pacf_lags)]\n","      })\n","\n","      wandb.log({\n","          'Significant_Lags_Summary': wandb.Table(dataframe=summary_df)\n","      })\n","\n","      return {\n","          self.ACF_LAGS_KEY: significant_acf_lags,\n","          self.PACF_LAGS_KEY: significant_pacf_lags\n","      }\n","\n","\n","\n","    def suggest_arima_orders(self, acf_values: np.ndarray, pacf_values: np.ndarray,\n","                        significant_lags: Dict[str, List[int]], d: int = 0) -> Dict[str, Tuple[int, int, int]]:\n","      try:\n","          suggestions = {}\n","\n","          # [Previous validation code remains the same]\n","          if not isinstance(significant_lags, dict) or self.ACF_LAGS_KEY not in significant_lags or self.PACF_LAGS_KEY not in significant_lags:\n","              raise ValueError(f\"significant_lags must be a dictionary with '{self.ACF_LAGS_KEY}' and '{self.PACF_LAGS_KEY}' keys\")\n","\n","          acf_sig_lags = sorted(significant_lags.get(self.ACF_LAGS_KEY, []))\n","          pacf_sig_lags = sorted(significant_lags.get(self.PACF_LAGS_KEY, []))\n","\n","          # Calculate all suggestions as before\n","          p_conservative = next((lag for lag in pacf_sig_lags if lag > 0), 0)\n","          q_conservative = next((lag for lag in acf_sig_lags if lag > 0), 0)\n","          suggestions['conservative'] = (p_conservative, d, q_conservative)\n","\n","          p_moderate = min(len([lag for lag in pacf_sig_lags if 0 < lag <= 10]), 3)\n","          q_moderate = min(len([lag for lag in acf_sig_lags if 0 < lag <= 10]), 3)\n","          suggestions['moderate'] = (p_moderate, d, q_moderate)\n","\n","          seasonal_p = self._find_seasonal_pattern(pacf_values)\n","          seasonal_q = self._find_seasonal_pattern(acf_values)\n","\n","          p_aggressive = min(max(p_moderate + 1, seasonal_p), 5)\n","          q_aggressive = min(max(q_moderate + 1, seasonal_q), 5)\n","          suggestions['aggressive'] = (p_aggressive, d, q_aggressive)\n","\n","          if seasonal_p > 0 or seasonal_q > 0:\n","              suggestions['seasonal'] = (\n","                  seasonal_p if seasonal_p > 0 else 1,\n","                  d,\n","                  seasonal_q if seasonal_q > 0 else 1\n","              )\n","\n","          # Create a single DataFrame for all ARIMA suggestions\n","          suggestions_df = pd.DataFrame([\n","            {\n","                'Approach': k.capitalize(),\n","                'p': v[0],\n","                'd': v[1],\n","                'q': v[2],\n","                'ARIMA_Order': f'ARIMA({v[0]},{v[1]},{v[2]})',\n","                'Description': self._get_approach_description(k, v[0], v[1], v[2]),\n","                'Complexity': self._get_complexity_score(v[0], v[1], v[2])\n","            }\n","            for k, v in suggestions.items()\n","          ])\n","\n","          # Sort by complexity\n","          suggestions_df = suggestions_df.sort_values('Complexity')\n","\n","          # Log enhanced table to wandb\n","          wandb.log({\n","              'ARIMA_Suggestions_Detail': wandb.Table(dataframe=suggestions_df)\n","          })\n","\n","          return suggestions\n","\n","      except Exception as e:\n","          print(f\"Error in suggest_arima_orders: {e}\")\n","          return {'conservative': (1, d, 1)}\n","\n","    def _get_approach_description(self, approach, p, d, q):\n","      descriptions = {\n","          'conservative': 'Minimal model using first significant lags',\n","          'moderate': 'Balanced model using first 10 lags',\n","          'aggressive': 'Complex model considering more lags',\n","          'seasonal': 'Model accounting for seasonal patterns'\n","      }\n","      return descriptions.get(approach.lower(), 'Custom approach')\n","\n","    def _get_complexity_score(self, p, d, q):\n","      return p + d + q  # Simple complexity score\n","\n","\n","    def _find_pattern_cutoff(self, values: np.ndarray, threshold: float = 0.1) -> int:\n","        \"\"\"Find where the ACF/PACF pattern cuts off\"\"\"\n","        for i in range(1, len(values)-1):\n","            if abs(values[i]) < threshold and abs(values[i+1]) < threshold:\n","                return i\n","        return min(5, len(values)-1)  # Default to 5 if no clear cutoff\n","\n","\n","\n","    def _find_seasonal_pattern(self, values: np.ndarray) -> int:\n","        \"\"\"Identify potential seasonal patterns in ACF/PACF\"\"\"\n","        peaks = []\n","        for i in range(2, len(values)-1):\n","            if (values[i] > values[i-1] and values[i] > values[i+1] and\n","                abs(values[i]) > 0.1):\n","                peaks.append(i)\n","\n","        if len(peaks) >= 2:\n","            # Look for regular spacing between peaks\n","            differences = np.diff(peaks)\n","            if len(set(differences)) == 1:\n","                return differences[0]\n","        return 0\n","\n","\n","\n","    def run_analysis(self, d=0):\n","      \"\"\"\n","      Run the complete analysis workflow.\n","      \"\"\"\n","      try:\n","          # Start timing\n","          start_time = datetime.now()\n","\n","          # Get system info\n","          import psutil\n","          import platform\n","          import sys\n","\n","          # Compute ACF and PACF\n","          acf_pacf_values = self.compute_acf_pacf()\n","\n","          # Plot ACF and PACF\n","          self.plot_acf_pacf(acf_pacf_values[self.ACF_KEY], acf_pacf_values[self.PACF_KEY])\n","\n","          # Find significant lags\n","          significant_lags = self.find_significant_lags(\n","              acf_pacf_values[self.ACF_KEY],\n","              acf_pacf_values[self.PACF_KEY]\n","          )\n","\n","          # Get ARIMA suggestions\n","          arima_suggestions = self.suggest_arima_orders(\n","              acf_pacf_values[self.ACF_KEY],\n","              acf_pacf_values[self.PACF_KEY],\n","              significant_lags,\n","              d=d\n","          )\n","\n","          # Calculate execution time\n","          execution_time = (datetime.now() - start_time).total_seconds()\n","\n","          # Get system metrics\n","          system_metrics = pd.DataFrame([{\n","              'CPU_Usage_Percent': psutil.cpu_percent(),\n","              'Memory_Usage_Percent': psutil.virtual_memory().percent,\n","              'Available_Memory_GB': round(psutil.virtual_memory().available / (1024**3), 2),\n","              'Total_Memory_GB': round(psutil.virtual_memory().total / (1024**3), 2),\n","              'Python_Version': platform.python_version(),\n","              'OS_Platform': platform.platform(),\n","              'CPU_Cores': psutil.cpu_count(),\n","              'Execution_Time_Seconds': execution_time\n","          }])\n","\n","          # Create comprehensive final summary\n","          all_stats_summary = pd.DataFrame([{\n","              'Total_ACF_Lags': len(significant_lags[self.ACF_LAGS_KEY]),\n","              'Total_PACF_Lags': len(significant_lags[self.PACF_LAGS_KEY]),\n","              'Number_of_ARIMA_Models': len(arima_suggestions),\n","              'Input_Series_Length': len(self.returns),\n","              'Differencing_Order': d,\n","              'Max_Lag_Analyzed': self.max_lags,\n","              'Data_Range': f\"{self.returns.index[0]} to {self.returns.index[-1]}\",\n","              'Analysis_Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","              'Execution_Time_Seconds': execution_time\n","          }])\n","\n","          # Log summaries to wandb\n","          wandb.log({\n","              'Analysis_Complete_Summary': wandb.Table(dataframe=all_stats_summary),\n","              'System_Performance_Metrics': wandb.Table(dataframe=system_metrics)\n","          })\n","\n","          # Log system metrics directly for tracking\n","          wandb.log({\n","              'CPU_Usage': psutil.cpu_percent(),\n","              'Memory_Usage': psutil.virtual_memory().percent,\n","              'Execution_Time': execution_time\n","          })\n","\n","          # Finish wandb run\n","          wandb.finish()\n","\n","          return {\n","              'significant_lags': significant_lags,\n","              'acf_pacf_values': acf_pacf_values,\n","              'arima_suggestions': arima_suggestions\n","          }\n","\n","      except Exception as e:\n","          print(f\"Error in run_analysis: {e}\")\n","          wandb.finish()\n","          raise e"],"metadata":{"id":"qXGOCFe9cseE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["analysis = TimeSeriesAnalysis(\n","            returns_series=df0,\n","            max_lags=200\n","        )\n","\n","        # Run the complete analysis\n","results = analysis.run_analysis()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":492},"id":"crHY1lwxc5B5","executionInfo":{"status":"ok","timestamp":1735308182448,"user_tz":-330,"elapsed":24393,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"}},"outputId":"03ecd3ef-681d-4077-81ec-def0a82fb07b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20241227_140237-vv60vkzb</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc/runs/vv60vkzb' target=\"_blank\">ACF_PACF_last_half_data_20241227_1402</a></strong> to <a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc' target=\"_blank\">https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc/runs/vv60vkzb' target=\"_blank\">https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc/runs/vv60vkzb</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CPU_Usage</td><td>▁</td></tr><tr><td>Execution_Time</td><td>▁</td></tr><tr><td>Memory_Usage</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CPU_Usage</td><td>25.7</td></tr><tr><td>Execution_Time</td><td>19.86537</td></tr><tr><td>Memory_Usage</td><td>15.2</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">ACF_PACF_last_half_data_20241227_1402</strong> at: <a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc/runs/vv60vkzb' target=\"_blank\">https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc/runs/vv60vkzb</a><br> View project at: <a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc' target=\"_blank\">https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc</a><br>Synced 5 W&B file(s), 0 media file(s), 14 artifact file(s) and 8 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20241227_140237-vv60vkzb/logs</code>"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"C36Tc8H73rvp"},"execution_count":null,"outputs":[]}]}