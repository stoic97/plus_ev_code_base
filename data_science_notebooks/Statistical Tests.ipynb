{"cells":[{"cell_type":"markdown","id":"3a32bd82-c66f-4747-ab79-2b10938f838f","metadata":{"id":"3a32bd82-c66f-4747-ab79-2b10938f838f"},"source":["# Statistical Tests for Time Series Analysis on NIFTY50 5 min OHLC Data ðŸ“ˆ\n","\n","## 1. Augmented Dickey-Fuller (ADF) Test ðŸŽ¯\n","\n","### Purpose\n","> Tests for stationarity in time series data (Critical for prediction)\n","\n","### Why Important\n","* **Model Prerequisites**\n","  - Essential for ARIMA modeling\n","  - Foundation for reliable predictions\n","\n","### Interpretation\n","| Result | Meaning | Action |\n","|--------|---------|--------|\n","| p < 0.05 | Stationary | Ready for modeling |\n","| p > 0.05 | Non-stationary | Need differencing |\n","\n","### Impact on Models\n","* **ARIMA**: Determines 'd' parameter directly\n","* **Transformers**: Guides data preprocessing strategy\n","\n","---\n","\n","## 2. ACF (Autocorrelation Function) ðŸ“Š\n","\n","### Purpose\n","> Reveals relationship between current and past values\n","\n","### Key Insights\n","* **Pattern Detection**\n","  - Series memory depth\n","  - Seasonal patterns\n","  - Trend strength\n","\n","### Pattern Interpretation\n","* **Slow Decay**: Strong trend present\n","* **Periodic Spikes**: Seasonal patterns exist\n","* **Quick Decay**: Weak autocorrelation\n","\n","### Model Implications\n","* **ARIMA**: Helps set 'q' (MA) parameter\n","* **Transformers**: Guides sequence length choice\n","\n","---\n","\n","## 3. PACF (Partial Autocorrelation Function) ðŸ”\n","\n","### Purpose\n","> Shows direct relationships between time points\n","\n","### Key Benefits\n","* **Direct Dependencies**\n","  - Pure lag relationships\n","  - Optimal lookback period\n","  - AR order identification\n","\n","### Pattern Reading\n","* **Significant Spikes**: Direct relationships\n","* **Cut-off Point**: Suggests AR order\n","* **Decay Pattern**: Complexity indicator\n","\n","### Model Applications\n","* **ARIMA**: Sets 'p' (AR) parameter\n","* **Transformers**: Guides attention window\n","\n","---\n","\n","## 4. Ljung-Box Test âš–ï¸\n","\n","### Purpose\n","> Validates residual randomness\n","\n","### Importance\n","* **Model Validation**\n","  - Tests assumptions\n","  - Checks pattern capture\n","  - Quality assurance\n","\n","### Results Guide\n","| p-value | Interpretation | Next Steps |\n","|---------|----------------|------------|\n","| > 0.05 | Good fit | Proceed with model |\n","| < 0.05 | Missing patterns | Model refinement needed |\n","\n","---\n","\n","## Trading Strategy Implementation ðŸ’¹\n","\n","### Data Properties Analysis\n","* **Pattern Understanding**\n","  - Price movement characteristics\n","  - Key time intervals\n","  - Preprocessing requirements\n","\n","### Model Selection Framework\n","| Pattern | Suggested Model | Why |\n","|---------|----------------|-----|\n","| Strong seasonality | ARIMA | Good for regular patterns |\n","| Complex patterns | Transformers | Better with non-linear relationships |\n","| High randomness | Feature enrichment | Need more predictive signals |\n","\n","### Parameter Optimization\n","1. **ARIMA Parameters**\n","   - p: From PACF analysis\n","   - d: From ADF test\n","   - q: From ACF analysis\n","\n","2. **Transformer Settings**\n","   - Sequence length\n","   - Attention window\n","   - Feature engineering scope\n","\n","---\n"]},{"cell_type":"code","execution_count":8,"id":"b876eda1-205f-479c-9f37-5e421531d74c","metadata":{"executionInfo":{"elapsed":440,"status":"ok","timestamp":1735210539695,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"},"user_tz":-330},"id":"b876eda1-205f-479c-9f37-5e421531d74c"},"outputs":[],"source":["# !pip install mlflow\n","import pandas as pd\n","import numpy as np\n","from statsmodels.tsa.stattools import adfuller, kpss, acf, pacf\n","from statsmodels.stats.diagnostic import acorr_ljungbox\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import gc\n","import os\n","# import mlflow"]},{"cell_type":"code","execution_count":9,"id":"RE-9632oAWRb","metadata":{"executionInfo":{"elapsed":443,"status":"ok","timestamp":1735210542462,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"},"user_tz":-330},"id":"RE-9632oAWRb"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":10,"id":"e911e999-e224-422a-8afa-85f3dac1608a","metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1735210543396,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"},"user_tz":-330},"id":"e911e999-e224-422a-8afa-85f3dac1608a"},"outputs":[],"source":["# Input File - Data 2014 to 2024 - 1min ohlc\n","# 6 Parts - Last 6month 5 min ohlc, last to last 6 month 5 min ohlc, in similar fashion 1 year and 2 year.\n","## created df1- df6 serieses"]},{"cell_type":"code","execution_count":30,"id":"9ae69678-d668-4e56-b9c0-7e3702cdbfec","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17599,"status":"ok","timestamp":1735212499239,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"},"user_tz":-330},"id":"9ae69678-d668-4e56-b9c0-7e3702cdbfec","outputId":"5327d1c9-4ef6-4fd3-c789-89a524fb36d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading and preprocessing data...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-30-8920b300950a>:55: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n","  resampled = df.resample(interval).agg({\n"]},{"output_type":"stream","name":"stdout","text":["\n","Creating and validating period datasets...\n","\n","Quality issues in last_6m:\n","- Found 124 time gaps > 6 minutes\n","\n","Quality issues in last_to_last_6m:\n","- Found 126 time gaps > 6 minutes\n","\n","Quality issues in last_1y:\n","- Found 250 time gaps > 6 minutes\n","\n","Quality issues in last_to_last_1y:\n","- Found 247 time gaps > 6 minutes\n","\n","Quality issues in last_2y:\n","- Found 497 time gaps > 6 minutes\n","\n","Quality issues in last_to_last_2y:\n","- Found 496 time gaps > 6 minutes\n","\n","Period Summaries:\n","======================================================================\n","\n","last_6m:\n","Date Range: 2024-02-28 15:25:00+05:30 to 2024-08-28 15:25:00+05:30\n","Records: 9043, Trading Days: 123\n","Quality Check: âœ—\n","\n","last_to_last_6m:\n","Date Range: 2023-08-28 15:25:00+05:30 to 2024-02-28 15:25:00+05:30\n","Records: 9388, Trading Days: 127\n","Quality Check: âœ—\n","\n","last_1y:\n","Date Range: 2023-08-28 15:25:00+05:30 to 2024-08-28 15:25:00+05:30\n","Records: 18430, Trading Days: 249\n","Quality Check: âœ—\n","\n","last_to_last_1y:\n","Date Range: 2022-08-29 09:15:00+05:30 to 2023-08-28 15:25:00+05:30\n","Records: 18537, Trading Days: 248\n","Quality Check: âœ—\n","\n","last_2y:\n","Date Range: 2022-08-29 09:15:00+05:30 to 2024-08-28 15:25:00+05:30\n","Records: 36966, Trading Days: 496\n","Quality Check: âœ—\n","\n","last_to_last_2y:\n","Date Range: 2020-08-28 15:25:00+05:30 to 2022-08-26 15:25:00+05:30\n","Records: 37011, Trading Days: 497\n","Quality Check: âœ—\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-30-8920b300950a>:151: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n","  df_0 = df_0.resample('5T').agg({\n","<ipython-input-30-8920b300950a>:151: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df_0 = df_0.resample('5T').agg({\n"]}],"source":["# Data Extraction\n","def resample_and_get_periods(csv_path, interval='5T'):\n","   \"\"\"\n","   Load data, resample to 5 min OHLC, perform quality checks, and split into periods\n","\n","   Parameters:\n","   - csv_path: path to CSV file\n","   - interval: resampling interval (default '5T' for 5 minutes)\n","\n","   Returns: Dictionary of quality-checked, resampled dataframes for different periods\n","   \"\"\"\n","   # Load data\n","   def load_and_clean(csv_path):\n","       df = pd.read_csv(csv_path)\n","       df['date'] = pd.to_datetime(df['date'])\n","       return df.set_index('date').sort_index()\n","\n","   # Quality checks\n","   def quality_checks(df, period_name):\n","       issues = []\n","\n","       # Check for missing values\n","       missing = df.isnull().sum()\n","       if missing.any():\n","           issues.append(f\"Missing values found: {missing[missing > 0]}\")\n","\n","       # Check for duplicates\n","       duplicates = df.index.duplicated().sum()\n","       if duplicates:\n","           issues.append(f\"Found {duplicates} duplicate timestamps\")\n","\n","       # Check for price anomalies\n","       price_std = df['close'].std()\n","       price_mean = df['close'].mean()\n","       outliers = df[abs(df['close'] - price_mean) > 3 * price_std]\n","       if not outliers.empty:\n","           issues.append(f\"Found {len(outliers)} potential price outliers\")\n","\n","       # Check for gaps in time series\n","       time_diff = df.index.to_series().diff()\n","       gaps = time_diff[time_diff > pd.Timedelta(minutes=6)]  # More than 6 min gap\n","       if not gaps.empty:\n","           issues.append(f\"Found {len(gaps)} time gaps > 6 minutes\")\n","\n","       # Print issues for this period\n","       if issues:\n","           print(f\"\\nQuality issues in {period_name}:\")\n","           for issue in issues:\n","               print(f\"- {issue}\")\n","\n","       return len(issues) == 0\n","\n","   # Resample to 5 min OHLC\n","   def resample_ohlc(df, interval):\n","       resampled = df.resample(interval).agg({\n","           'open': 'first',\n","           'high': 'max',\n","           'low': 'min',\n","           'close': 'last',\n","           'volume': 'sum'\n","       })\n","       return resampled.dropna()  # Remove any incomplete periods\n","\n","   print(\"Loading and preprocessing data...\")\n","   df = load_and_clean(csv_path)\n","\n","   # Resample full dataset\n","   df_resampled = resample_ohlc(df, interval)\n","\n","   # Get end date\n","   end_date = df_resampled.index.max()\n","\n","   # Define periods and create slices\n","   periods = {\n","       'last_6m': (end_date - pd.DateOffset(months=6), end_date),\n","       'last_to_last_6m': (end_date - pd.DateOffset(months=12),\n","                          end_date - pd.DateOffset(months=6)),\n","       'last_1y': (end_date - pd.DateOffset(years=1), end_date),\n","       'last_to_last_1y': (end_date - pd.DateOffset(years=2),\n","                          end_date - pd.DateOffset(years=1)),\n","       'last_2y': (end_date - pd.DateOffset(years=2), end_date),\n","       'last_to_last_2y': (end_date - pd.DateOffset(years=4),\n","                          end_date - pd.DateOffset(years=2))\n","   }\n","\n","   datasets = {}\n","   print(\"\\nCreating and validating period datasets...\")\n","\n","   for name, (start, end) in periods.items():\n","       # Slice data\n","       period_data = df_resampled[start:end].copy()\n","\n","       # Perform quality checks\n","       is_clean = quality_checks(period_data, name)\n","\n","       # Store data and metadata\n","       datasets[name] = {\n","           'data': period_data,\n","           'metadata': {\n","               'start_date': period_data.index.min(),\n","               'end_date': period_data.index.max(),\n","               'records': len(period_data),\n","               'trading_days': len(set(period_data.index.date)),\n","               'quality_passed': is_clean\n","           }\n","       }\n","\n","   # Print summary\n","   print(\"\\nPeriod Summaries:\")\n","   print(\"=\"*70)\n","   for name, dataset in datasets.items():\n","       meta = dataset['metadata']\n","       print(f\"\\n{name}:\")\n","       print(f\"Date Range: {meta['start_date']} to {meta['end_date']}\")\n","       print(f\"Records: {meta['records']}, Trading Days: {meta['trading_days']}\")\n","       print(f\"Quality Check: {'âœ“' if meta['quality_passed'] else 'âœ—'}\")\n","\n","   return datasets\n","\n","# Usage\n","REPO_PATH = \"/content/drive/MyDrive/Colab Notebooks/plusEV-\"\n","csv_path = os.path.join(REPO_PATH, \"nifty50_1min_2015_to_2024.csv\")\n","datasets = resample_and_get_periods(csv_path)\n","\n","# # Access data for a period\n","# df0 = datasets['last_6m']['data']\n","# last_6m_metadata = datasets['last_6m']['metadata']\n","# df0 = datasets['last_to_last_6m']['data']\n","# df0 = datasets['last_1y']['data']\n","# df0 = datasets['last_to_last_1y']['data']\n","# df0 = datasets['last_2y']['data']\n","# df0 = datasets['last_to_last_2y']['data']\n","# df0[\"Return\"] = df0[\"close\"].pct_change()\n","# df0 = df0[\"Return\"].dropna()\n","# df2[\"Return\"] = df2[\"close\"].pct_change()\n","# df2 = df2[\"Return\"].dropna()\n","# df3[\"Return\"] = df3[\"close\"].pct_change()\n","# df3 = df3[\"Return\"].dropna()\n","# df4[\"Return\"] = df4[\"close\"].pct_change()\n","# df4 = df4[\"Return\"].dropna()\n","# df5[\"Return\"] = df5[\"close\"].pct_change()\n","# df5 = df5[\"Return\"].dropna()\n","# df6[\"Return\"] = df6[\"close\"].pct_change()\n","# df6 = df6[\"Return\"].dropna()\n","\n","# print(df1)\n","\n","df_0 = pd.read_csv(csv_path)\n","df_0['date'] = pd.to_datetime(df_0['date'])\n","df_0 = df_0.set_index('date').sort_index()\n","df_0 = df_0.resample('5T').agg({\n","    'open': 'first',\n","    'high': 'max',\n","    'low': 'min',\n","    'close': 'last',\n","    'volume': 'sum'\n","}).fillna(method='ffill')\n","df_0['Return'] = df_0['close'].pct_change()\n","df0 = df_0[\"Return\"].dropna()"]},{"cell_type":"code","execution_count":31,"id":"66a75e00-8420-4543-951a-10ab1860bcb5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1735212521656,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"},"user_tz":-330},"id":"66a75e00-8420-4543-951a-10ab1860bcb5","outputId":"26305e14-0889-429c-c8d3-b14d24a623e6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["43917"]},"metadata":{},"execution_count":31}],"source":["midpoint = len(df0) // 2\n","df0 = df0[:midpoint]\n","gc.collect()"]},{"cell_type":"code","source":["df0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"_qMCzwhjd4wv","executionInfo":{"status":"ok","timestamp":1735212521656,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"}},"outputId":"4930157d-8d89-476c-dd6e-46266b4dd8b1"},"id":"_qMCzwhjd4wv","execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["date\n","2015-01-09 09:20:00+05:30   -0.000024\n","2015-01-09 09:25:00+05:30   -0.000825\n","2015-01-09 09:30:00+05:30   -0.000681\n","2015-01-09 09:35:00+05:30   -0.000609\n","2015-01-09 09:40:00+05:30    0.000254\n","                               ...   \n","2019-11-04 00:00:00+05:30    0.000000\n","2019-11-04 00:05:00+05:30    0.000000\n","2019-11-04 00:10:00+05:30    0.000000\n","2019-11-04 00:15:00+05:30    0.000000\n","2019-11-04 00:20:00+05:30    0.000000\n","Freq: 5min, Name: Return, Length: 506773, dtype: float64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Return</th>\n","    </tr>\n","    <tr>\n","      <th>date</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2015-01-09 09:20:00+05:30</th>\n","      <td>-0.000024</td>\n","    </tr>\n","    <tr>\n","      <th>2015-01-09 09:25:00+05:30</th>\n","      <td>-0.000825</td>\n","    </tr>\n","    <tr>\n","      <th>2015-01-09 09:30:00+05:30</th>\n","      <td>-0.000681</td>\n","    </tr>\n","    <tr>\n","      <th>2015-01-09 09:35:00+05:30</th>\n","      <td>-0.000609</td>\n","    </tr>\n","    <tr>\n","      <th>2015-01-09 09:40:00+05:30</th>\n","      <td>0.000254</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-04 00:00:00+05:30</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-04 00:05:00+05:30</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-04 00:10:00+05:30</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-04 00:15:00+05:30</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-04 00:20:00+05:30</th>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>506773 rows Ã— 1 columns</p>\n","</div><br><label><b>dtype:</b> float64</label>"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# Add this at the start of your notebook\n","def setup_wandb():\n","    try:\n","        import wandb\n","        # Check if already logged in\n","        if wandb.api.api_key is None:\n","            # Your API key\n","            WANDB_API_KEY = \"641b305133f7d8345e710ecf6c9d83fea7e225f1\"\n","            os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n","\n","        print(\"WandB setup complete!\")\n","        return True\n","    except Exception as e:\n","        print(f\"Error setting up WandB: {str(e)}\")\n","        return False\n","\n","# Use it in your notebook\n","setup_wandb()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZT81RuYsw6X","executionInfo":{"status":"ok","timestamp":1735212523366,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"}},"outputId":"840cea8b-51f5-4c60-96fc-5dab48f66234"},"id":"CZT81RuYsw6X","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["WandB setup complete!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","execution_count":34,"id":"21129155-9acb-4a3a-a970-d75d02531ec1","metadata":{"id":"21129155-9acb-4a3a-a970-d75d02531ec1","outputId":"3dec1cba-8d04-4bd9-8361-75cae63d71df","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1735212686426,"user_tz":-330,"elapsed":161265,"user":{"displayName":"Pawan Rathore","userId":"07037767808853943673"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20241226_112844-zxudrzkd</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc/runs/zxudrzkd' target=\"_blank\">first_half_data_20241226_1128</a></strong> to <a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc' target=\"_blank\">https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc/runs/zxudrzkd' target=\"_blank\">https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc/runs/zxudrzkd</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Stationarity Tests:\n","ADF Test: Stationary\n","P-value: 0.0000\n","\n","Differencing Required:\n","KPSS Test: 0 differences\n","ADF Test: 0 differences\n","PP Test: 0 differences\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">first_half_data_20241226_1128</strong> at: <a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc/runs/zxudrzkd' target=\"_blank\">https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc/runs/zxudrzkd</a><br> View project at: <a href='https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc' target=\"_blank\">https://wandb.ai/pawan-rathore15-97-plusev/Time%20Series%20Analysis%20of%20Nifty50%205%20min%20ohlc</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 6 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20241226_112844-zxudrzkd/logs</code>"]},"metadata":{}}],"source":["import pandas as pd\n","import numpy as np\n","from statsmodels.tsa.stattools import adfuller\n","from pmdarima.arima.utils import ndiffs  # ndiffs is from pmdarima\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import wandb\n","from scipy import stats\n","from datetime import datetime\n","\n","plt.style.use('default')\n","\n","def analyze_stationarity(returns_series, title=\"Returns Analysis\", sample_size=10000):\n","    try:\n","        wandb.init(\n","            project=\"Time Series Analysis of Nifty50 5 min ohlc\",\n","            name=f\"first_half_data_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n","            group=\"Stationarity Analysis\",\n","            config={\n","                \"sample_size\": sample_size,\n","                \"data_points\": len(returns_series),\n","                \"analysis_type\": \"stationarity\",\n","                \"data_range\": f\"{returns_series.index[0]} to {returns_series.index[-1]}\"\n","            },\n","            tags=[\"stationarity_test\", \"adf_analysis\", \"basic_statistics\",\"ARIMA_parameter_calcualtion\",\"nDiff_method\" ]\n","        )\n","\n","        # Efficient sampling for large datasets\n","        if len(returns_series) > sample_size:\n","            plot_data = returns_series.sample(n=sample_size, random_state=42)\n","        else:\n","            plot_data = returns_series\n","\n","        # Run ADF Test on chunks if data is too large\n","        if len(returns_series) > 100000:\n","            chunk_size = 100000\n","            chunks = [returns_series[i:i+chunk_size] for i in range(0, len(returns_series), chunk_size)]\n","            adf_results = []\n","            for chunk in chunks[:3]:\n","                adf_results.append(adfuller(chunk))\n","            # Use the median of test results\n","            adf_result = (\n","                np.median([r[0] for r in adf_results]),\n","                np.median([r[1] for r in adf_results]),\n","                np.median([r[2] for r in adf_results]),\n","                None,\n","                {k: np.median([r[4][k] for r in adf_results]) for k in adf_results[0][4].keys()}\n","            )\n","        else:\n","            adf_result = adfuller(returns_series)\n","\n","        additional_stats = {\n","            'quartiles': {\n","                'q1': float(returns_series.quantile(0.25)),\n","                'q2': float(returns_series.quantile(0.50)),  # median\n","                'q3': float(returns_series.quantile(0.75))\n","            },\n","            'percentiles': {\n","                'p1': float(returns_series.quantile(0.01)),\n","                'p5': float(returns_series.quantile(0.05)),\n","                'p95': float(returns_series.quantile(0.95)),\n","                'p99': float(returns_series.quantile(0.99))\n","            },\n","            'range': {\n","                'min': float(returns_series.min()),\n","                'max': float(returns_series.max()),\n","                'range': float(returns_series.max() - returns_series.min())\n","            },\n","            'distribution': {\n","                'jarque_bera': stats.jarque_bera(returns_series),\n","                'shapiro': stats.shapiro(returns_series.sample(min(5000, len(returns_series)))),\n","                'variation_coefficient': float(returns_series.std() / returns_series.mean() if returns_series.mean() != 0 else np.nan)\n","            }\n","        }\n","\n","        ndiffs_results = {\n","            'kpss_diffs': ndiffs(returns_series, test='kpss', max_d=2),\n","            'adf_diffs': ndiffs(returns_series, test='adf', max_d=2),\n","            'pp_diffs': ndiffs(returns_series, test='pp', max_d=2)\n","        }\n","\n","        # Memory-efficient plotting\n","        fig = plt.figure(figsize=(15, 10))\n","\n","        # Plot 1: Returns Time Series\n","        plt.subplot(221)\n","        plt.plot(plot_data.index, plot_data.values, linewidth=0.5)\n","        plt.title(f\"{title} - Time Series Plot\")\n","        plt.xlabel(\"Time\")\n","        plt.ylabel(\"Returns\")\n","\n","        # Plot 2: Returns Distribution\n","        plt.subplot(222)\n","        sns.histplot(data=plot_data.values, kde=True)\n","        plt.title(\"Returns Distribution with KDE\")\n","        plt.xlabel(\"Return Value\")\n","\n","        # Plot 3: QQ Plot\n","        plt.subplot(223)\n","        stats.probplot(plot_data.values, dist=\"norm\", plot=plt)\n","        plt.title(\"Q-Q Plot\")\n","\n","        # Plot 4: Box Plot\n","        plt.subplot(224)\n","        sns.boxplot(y=plot_data.values)\n","        plt.title(\"Box Plot of Returns\")\n","\n","        plt.tight_layout()\n","\n","        # Calculate statistics\n","        results = {\n","            'test_statistic': float(adf_result[0]),\n","            'p_value': float(adf_result[1]),\n","            'critical_values': adf_result[4],\n","            'is_stationary': adf_result[1] < 0.05,\n","            'statistics': {\n","                'mean': float(returns_series.mean()),\n","                'std': float(returns_series.std()),\n","                'skew': float(returns_series.skew()),\n","                'kurtosis': float(returns_series.kurtosis())\n","            }\n","        }\n","\n","        statistics_summary = pd.DataFrame({\n","            'Metric': [\n","                'ADF Test Statistic', 'ADF P-value', 'Is Stationary (1=Yes, 0=No)',\n","                'Mean', 'Standard Deviation', 'Skewness', 'Kurtosis',\n","                'Q1', 'Median', 'Q3',\n","                'P1', 'P5', 'P95', 'P99',\n","                'Min', 'Max', 'Range',\n","                'Jarque-Bera Statistic', 'Jarque-Bera P-value',\n","                'Shapiro Statistic', 'Shapiro P-value',\n","                'Variation Coefficient',\n","                'KPSS Diffs Required', 'ADF Diffs Required', 'PP Diffs Required'\n","            ],\n","            'Value': [\n","                float(results['test_statistic']),\n","                float(results['p_value']),\n","                float(results['is_stationary']),  # Convert boolean to float\n","                float(results['statistics']['mean']),\n","                float(results['statistics']['std']),\n","                float(results['statistics']['skew']),\n","                float(results['statistics']['kurtosis']),\n","                float(additional_stats['quartiles']['q1']),\n","                float(additional_stats['quartiles']['q2']),\n","                float(additional_stats['quartiles']['q3']),\n","                float(additional_stats['percentiles']['p1']),\n","                float(additional_stats['percentiles']['p5']),\n","                float(additional_stats['percentiles']['p95']),\n","                float(additional_stats['percentiles']['p99']),\n","                float(additional_stats['range']['min']),\n","                float(additional_stats['range']['max']),\n","                float(additional_stats['range']['range']),\n","                float(additional_stats['distribution']['jarque_bera'][0]),\n","                float(additional_stats['distribution']['jarque_bera'][1]),\n","                float(additional_stats['distribution']['shapiro'][0]),\n","                float(additional_stats['distribution']['shapiro'][1]),\n","                float(additional_stats['distribution']['variation_coefficient']),\n","                float(ndiffs_results['kpss_diffs']),\n","                float(ndiffs_results['adf_diffs']),\n","                float(ndiffs_results['pp_diffs'])\n","            ]\n","        })\n","\n","        wandb.log({\n","            \"time_series_plot\": wandb.Image(plt.subplot(221)),\n","            \"distribution_plot\": wandb.Image(plt.subplot(222)),\n","            \"qq_plot\": wandb.Image(plt.subplot(223)),\n","            \"box_plot\": wandb.Image(plt.subplot(224)),\n","            \"combined_plots\": wandb.Image(fig),\n","            \"statistics_table\": wandb.Table(dataframe=statistics_summary)\n","        })\n","\n","        # Enhanced printing\n","        print(\"\\nStationarity Tests:\")\n","        print(f\"ADF Test: {'Stationary' if results['is_stationary'] else 'Non-stationary'}\")\n","        print(f\"P-value: {results['p_value']:.4f}\")\n","        print(\"\\nDifferencing Required:\")\n","        print(f\"KPSS Test: {ndiffs_results['kpss_diffs']} differences\")\n","        print(f\"ADF Test: {ndiffs_results['adf_diffs']} differences\")\n","        print(f\"PP Test: {ndiffs_results['pp_diffs']} differences\")\n","\n","        wandb.finish()\n","        return results, additional_stats, ndiffs_results, fig\n","\n","    except Exception as e:\n","        print(f\"Error in analysis: {str(e)}\")\n","        if wandb.run is not None:\n","            wandb.finish()\n","        return None, None, None, None\n","\n","# Usage\n","results, additional_stats, ndiffs_results, fig = analyze_stationarity(df0)\n","plt.close(fig)"]},{"cell_type":"code","source":[],"metadata":{"id":"LAJbIoNsQf3J"},"id":"LAJbIoNsQf3J","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"_Q00F1YEB5WP"},"id":"_Q00F1YEB5WP","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python","language":"python","name":"base"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"}},"nbformat":4,"nbformat_minor":5}